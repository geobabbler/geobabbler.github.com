<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: GDAL | geoMusings]]></title>
  <link href="http://blog.geomusings.com/blog/categories/gdal/atom.xml" rel="self"/>
  <link href="http://blog.geomusings.com/"/>
  <updated>2014-07-09T16:52:57-04:00</updated>
  <id>http://blog.geomusings.com/</id>
  <author>
    <name><![CDATA[Bill Dollins]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Personal Geospatial Workflows, May 2014 Edition]]></title>
    <link href="http://blog.geomusings.com/2014/05/20/personal-geospatial-workflows/"/>
    <updated>2014-05-20T08:21:00-04:00</updated>
    <id>http://blog.geomusings.com/2014/05/20/personal-geospatial-workflows</id>
    <content type="html"><![CDATA[<p>I have been spending the past few weeks dealing more with data and mapping than I have in quite a while. It's given me a chance to regain my footing with map-making, reconnect with some end-user tools like <a href="http://www.arc2earth.com">Arc2Earth</a>, and build a little more proficiency with things like <a href="http://www.gdal.org/">GDAL</a>, <a href="http://qgis.org">QGIS</a>, and <a href="https://www.mapbox.com/tilemill/">TileMill</a>. Of course, I've been able to sneak in some coding as I've identified gaps in my workflow.</p>

<p>In a nutshell, I am building base maps for use on disconnected mobile devices. There are two styles of base maps; imagery (really more of an imagery/vector hybrid) and a high-contrast map for use on the outdoor devices and sourced only from vector data. In both cases, I am building MBTiles databases to support the requirement for disconnected operations and to provide consistency in data size and performance.</p>

<p>For the imagery base maps, I was faced with following a data request process that may or may not have resulted in getting imagery in a timely fashion. Alternatively, I was presented with the option of using a tiled map service to get the imagery. Given that I was just making basemaps, this would have been acceptable but for the spotty speed and reliability of the network connection. The ideal solution would be to get only the tiles I need, store them locally, create a geo-referenced image from them, and build a virtual raster table (VRT) for each level.</p>

<!--more-->


<p>Downloading the tiles was easy, but for the VRT to work, each tile needed to be geo-referenced. It was fairly easy to modify the venerable <a href="http://www.maptiler.org/google-maps-coordinates-tile-bounds-projection/globalmaptiles.py">globalmaptiles.py</a> to include a routine to create world file parameters for a specified tile. With this, I was able to write out an affine transformation world file for each tile I downloaded. I rolled this whole process up into a <a href="https://github.com/geobabbler/tile-grab">Python script that's available here</a>. Please note that my goal was to create a VRT, so the script flattens out the tiling scheme so that all images are under the appropriate "Z" directory. (This particular server was an ArcGIS Server but the script doesn't care as long as you can provide a valide URL template.)</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bat'><span class='line'>python tile_grab.py -b <span class="m">-158</span>;<span class="m">21</span>;<span class="m">-157</span>;<span class="m">22</span> -d E:\tiles\oahu_img\a -i false -z <span class="m">6</span> -u http:<span class="n">//www.someserver.net/arcgis/rest/services/ImagerySvc/MapServer/tile/{z}/{y}/{x}.png</span>
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>With the tiles downloaded and geo-referenced, it was easy to use the gdalbuildvrt utility to generate the VRT, which can be used in QGIS, TileMill, and ArcGIS Desktop as you prefer.</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bat'><span class='line'>gdalbuildvrt <span class="m">6</span>.vrt <span class="m">6</span><span class="n">/*.png</span>
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>It seems a little odd to use tiles to make tiles, but I needed to add some additional data and styling to make the maps do what I needed to do. The downloaded tiles were just a stand-in for what would have been a standard raster data source. The range of useful resolution for a set of tiles is pretty narrow so you'll probably need to grab a few levels and, even then, you'll need to be careful how you use them. In most cases, using local raster/imagery is better but using tiles was fine for my use case and helped mitigate a byzantine data acquisition process. Here's how I set the ranges in ArcGIS (left) and TileMill (right):</p>

<p style="text-align:center;"> <img src="http://blog.geomusings.com/images/posts/vrt_zoom2.png" /></p>

<p>Using this approach, I was able to successfully generate my maps using either of two technology mixes. I succeeded in using both TileMill and ArcGIS/Arc2Earth to generate my maps. I ended up doing most of the work in Arc2Earth due to the availability of command-line tools that helped me optimize performance.</p>

<p>Before attempting this method, it's important to make sure that you are not violating any terms of service, license agreements, or attribution requirements in doing so. I knew this wasn't an issue in my case, but such questions need to be answered before you start grabbing data.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Checking out the GDAL/OGR Plugin for ArcGIS]]></title>
    <link href="http://blog.geomusings.com/2013/01/22/checking-out-the-gdal-slash-ogr-plugin-for-arcgis/"/>
    <updated>2013-01-22T13:29:00-05:00</updated>
    <id>http://blog.geomusings.com/2013/01/22/checking-out-the-gdal-slash-ogr-plugin-for-arcgis</id>
    <content type="html"><![CDATA[<p>A while back, I <a href="http://blog.geomusings.com/2012/09/18/still-jonesing-for-ziggis-try-this-ogr-plug-in-for-arcgis/">blogged</a> the availability of a <a href="http://www.gdal.org/">GDAL/OGR</a> <a href="https://github.com/RBURHUM/arcgis-ogr/">plug-in for ArcGIS</a> desktop by <a href="http://www.linkedin.com/profile/view?id=14926439&amp;locale=en_US">Ragi Burhum at AmigoCloud</a>. At the time, I was hoping to dig into it fairly quickly but that didn't happen and I'm finally getting to it. Anyone who has followed this blog for a while knows that I have had <a href="http://blog.geomusings.com/2006/12/17/postgis-and-arcgis-9.1/">more</a> than a <a href="http://blog.geomusings.com/2007/07/10/consuming-georss-in-arcmap-with-inmemoryworkspacefactory/">passing</a> <a href="http://blog.geomusings.com/2012/10/03/cutting-tiles-for-arcgis-server-using-tilemill/">interest</a> in <a href="http://blog.geomusings.com/2010/06/02/importing-data-from-geocommons-into-arcmap/">integrating</a> new <a href="http://blog.geomusings.com/2011/03/02/announcing-weogeo-tools-for-arcgis/">data</a> <a href="http://blog.geomusings.com/2012/08/24/togeojson-and-towkt-for-the-esri-fgdb-api/">sources</a> <a href="http://blog.geomusings.com/2011/08/09/taking-a-look-at-pgmap/">with</a> <a href="http://blog.geomusings.com/2011/11/15/fgeojson/">ArcGIS</a> over the years. This comes from the fact that, as a technology geek, I am fascinated by all forms of technology and enjoy the process of integration and, as a consultant providing services to the Federal Government, most of my customers have standardized on Esri tools. Integrations such as GeoRSS, PostGIS, GeoCommons and GeoJSON have directly benefitted my customers for real-world applications so I continue look for ways to remove the barriers between them and the data they seek.</p>

<div style="text-align:center;"><img src="http://images-mediawiki-sites.thefullwiki.org/07/3/6/0/1583563936968042.png" /></div>




<!--more-->


<p>The GDAL/OGR plug-in caught my attention because it purports to add support for any format supported by GDAL and OGR, similar to the way <a href="http://qgis.org">QGIS</a> leverages them for a wide variety of format support. To get going with it, I downloaded the source and built it in Visual Studio 2010. I only ran into a couple of minor issues. First, a had previously installed the Windows build of OGR on my machine using the <a href="http://www.gisinternals.com/sdk/PackageList.aspx?file=release-1600-gdal-1-9-2-mapserver-6-2-0.zip">distribution from GIS Internals</a>. The project as it came down from GitHub couldn't find the OGR and OSR bindings for C#, so I had to resolve that trivial issue. Next, the plug-in was built for use in ArcGIS 10.1 but I was using 10.0. Because some new interfaces were introduced, the <a href="https://github.com/RBURHUM/arcgis-ogr/blob/master/src/OGRPlugin/OGRPlugin/ogrplugin_utils.cs">current code</a> contains a declaration of  type ISpatialReferenceFactory4, which is a 10.1 interface. I needed to change that to ISpatialReferenceFactory3 to make it work with 10.0. That has been the only change I have needed to make so far to account for the version differences. I plan to add a compiler directive in my fork of the project to account for that and submit it back once I can test it.</p>

<p>As I said before, I previously had installed GDAL/OGR so it was already on my machine and my GDAL_DATA environment variable was set. When I built the plug-in and attempted to use it in ArcMap, it threw an error when I tried adding a GeoJSON layer (also with SpatiaLite) that it could not find my gcs.csv file, which is in my GDAL_DATA location. With a little investigation, I found that the code was resetting that variable at runtime to point to the location of the plug-in binary. I copied the files there and it worked well from then on. I'll probably try to add a way to check for the existence of that variable before setting it. None of these issues were major and I think they were reasonable design choices up front so I am not concerned by them.</p>

<p>At that point, I was able to quickly add GeoJSON and SpatiaLite layers to my data frame in ArcMap. This is pretty exciting to me since the ability to support a wide range of data types was a long-standing goal of zigGIS and I'm glad that Ragi has conquered that with this work.</p>

<p>Because the layers are added using a plug-in workspace, they are full read-only citizens inside ArcGIS. For example, I was able to wire up a couple of models using ModelBuilder and execute clips (clipping a GeoJSON layer with a SpatiaLite layer) and buffers and simple tests. I'm really not a huge ModelBuilder user but I thought it would be a good way to test things out.</p>

<div style="text-align:center;">
<img src="http://blog.geomusings.com/images/posts/buffer.png" />
<div style="text-align:center;font-size: 14px;">Model to test a simple buffer<br/><br/></div></div>


<p>The model above produced a 50-foot buffer around Amtrak rail lines from NTAD 2012 in GeoJSON format. The resultant buffer was written to a file geodatabase. As you can see from the image below, it worked like a charm.</p>

<div style="text-align:center;">
<img src="http://blog.geomusings.com/images/posts/buffer_result_small.png" />
<div style="text-align:center;font-size: 14px;">Results of the buffer model.<br/><br/></div></div>


<p>I achieved similar success with a clip operation so I'm sufficiently confident in trying to package the plug-in up and put it in the hands of some of the analysts with whom I work. All-in-all, the plug-in is a nice piece of work. It's still not fully baked but it's a very solid start and deserves a closer look if you're looking to expand the reach of your ArcGIS investment.</p>
]]></content>
  </entry>
  
</feed>
