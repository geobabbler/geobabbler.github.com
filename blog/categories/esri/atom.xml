<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: ESRI | geoMusings]]></title>
  <link href="http://blog.geomusings.com/blog/categories/esri/atom.xml" rel="self"/>
  <link href="http://blog.geomusings.com/"/>
  <updated>2012-12-19T14:13:06-05:00</updated>
  <id>http://blog.geomusings.com/</id>
  <author>
    <name><![CDATA[Bill Dollins]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[AGIO Puts the Data First]]></title>
    <link href="http://blog.geomusings.com/2011/03/24/AGIO-Puts-the-Data-First/"/>
    <updated>2011-03-24T00:00:00-04:00</updated>
    <id>http://blog.geomusings.com/2011/03/24/AGIO-Puts-the-Data-First</id>
    <content type="html"><![CDATA[<p>I read <a href="http://www.gisuser.com/content/view/23022/222/">Learon Dalby's latest GISuser.com expert column</a> (disclosure: I am a contributor there also) with great interest since it addresses an issue with which I have worked closely over the years: availability of GIS data in a time of crisis. Over the years, the proliferation of "operating pictures" (you're not in style unless you have your own <a href="http://www.mitre.org/work/tech_papers/tech_papers_07/07_0093/">UDOP</a>) and other systems has obscured the fact that the data is really what matters. Certain segments of the community, especially those more focused on man-made disasters rather than the natural variety, have gotten very good at putting multiple layers of technology, services, security, policy, etc. between GIS data and the people who need it. <!--more--></p>

<p>The problem with with all of this is that these systems tend to be very fragile under stress (exactly the kinds of stress that one can expect during an actual crisis). To mitigate that, we add scalability, complexity and cost to build out large, highly-available systems to serve out a small amount of data.</p>

<p>[caption id="attachment_1593" align="aligncenter" width="416" caption="Is it this easy to get to your GIS data?"]<img alt="" class="size-full wp-image-1593" height="278" src="http://geobabble.files.wordpress.com/2011/03/buffet.png" title="Is it this easy to get to your GIS data?" width="416" />[/caption]</p>

<p>As Learon and Arkansas demonstrate, there is another approach and it is simply making GIS data as open and <em>directly</em> available as possible. This isn't always sexy (Shapefiles via FTP?!?!) but can be effective. Additionally, it touches upon <a href="http://geobabble.wordpress.com/2010/09/16/be-the-crowd/">an issue I raised last year</a>. Some of the best GIS data in existence is that which is created and maintained at the local government level (one might even call it "authoritative"), but that data is not always available. Arkansas is very realistic when they say that people most likely won't look to their GIS servers first and so they try to push that data to the places people will go to look (<a href="http://maps.google.com">Google</a>, <a href="http://www.bing.com/maps/">Bing</a>, <a href="http://geocommons.com/search?model=&amp;query=AGIO">GeoCommons</a>, <a href="http://www.esri.com">Esri</a>, <a href="http://www.mapquest.com/">MapQuest</a>) in formats that are the most universally accessible (shapefiles, KML, ATOM).</p>

<p>This is a low-level, and somewhat low-tech, form of data sharing and interoperability but, in a time of extended economic stress, Arkansas' GIS data is available and up-to-date. They have made the hurdles to get that data as low as possible and, in so doing, have raised the bar higher when judging data openness and availability.</p>

<p>Put that in your COP and view it.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Ten-Second Tidy]]></title>
    <link href="http://blog.geomusings.com/2010/12/10/Ten-Second-Tidy/"/>
    <updated>2010-12-10T00:00:00-05:00</updated>
    <id>http://blog.geomusings.com/2010/12/10/Ten-Second-Tidy</id>
    <content type="html"><![CDATA[<p>Things have been a bit hectic the last few weeks and that's left little time for blogging. Quite a bit has happened so I thought I'd do a little round-up (if for no other reason than to clear my own head).</p>

<p><iframe width="560" height="420" src="http://www.youtube.com/embed/cJa7P6dfmco?color=white&theme=light"></iframe></p>

<p>In no particular order:</p>

<p><strong>Steve Coast to Microsoft</strong> (I told you it had been a while) - Firstly, congratulations to Steve (#sincerity).  Secondly, this clearly is the final proof that crowd-sourced data in general, and OpenStreetMaps (sic) in particular, <a href="http://geobabble.wordpress.com/2010/09/16/be-the-crowd/">has no real value when compared to "authoritative" data sources</a> (#sarcasm).</p>

<p><strong>Google Fusion Tables</strong> - The only real problem at this point is the size limitation but, otherwise, this will be a game-changer for storing and sharing data. In its current form, it's already fairly easy to push your data up and expose it through Google's APIs. It'll be interesting to see if it gets easier. Support for spatial queries hints at some analytical capability, too. Speaking of which...</p>

<p><strong>Analytics in GeoCommons</strong> - This is one to watch. They are debuting a new function each day <a href="http://blog.fortiusone.com/2010/12/06/the-12-analytics-of-christmas/">on their blog</a>. FortiusOne builds their platform API-first, UI-second so everything they are showing should be exposed through their APIs. This will be a huge step in moving cloud-based geospatial technology from the "bit-bucket" stage to having a more complete workflow on the cloud infrastructure.</p>

<!--more-->


<p><strong>Arc2Earth Data Services and Arc2Cloud</strong> - Continuing the theme of building a complete workflow, <a href="http://www.arc2earth.com">Arc2Earth</a> is working on exposing a <a href="http://www.arc2earth.com/services/data-services/">complete range of Google geospatial services</a> to ArcGIS Desktop users. It's no secret that I'm a fan of Arc2Earth (and <a href="http://www.zekiah.com">my company</a> is a reseller), but this represents a big expansion of capability. Google's cloud infrastructure works differently that Amazon's and I think what <a href="http://beta.arc2cloud.com/">Arc2Earth is doing</a> is important because it will open up another channel for users and enable them to <a href="http://geobabble.wordpress.com/2010/07/26/clouds/">make choices based on their needs and requirements</a>.</p>

<p><strong>WeoGeo</strong> - <a href="http://www.weogeo.com">These guys</a> never sit still either. They've got some changes coming up that will greatly increase flexibility for managing spatial data on a cloud infrastructure. Taken together with the previous two entries on GeoCommons and Arc2Earth, I see a lot of innovation in cloud-based GIS really being driven by small, focused companies. This is not simply "push your server to an AMI and keep working." (Although that approach can have some utility.) Each of these companies is trying to figure out how to leverage the unique capabilities of cloud infrastructures to build new workflows and expand capability for users. And, it's important to note, they are making headway.</p>

<p><strong>WhereCampDC</strong> - Obviously, judging from the <a href="http://wherecampdc.org/">web site</a>, it's still in the early planning stages but I'm excited by the idea. This is exactly the kind of independent event that this area needs. I have always been baffled by the lack of such events in this area, especially given the level of geospatial activity around here.</p>

<p><strong>Google Earth 6</strong> - The <a href="http://www.google.com/earth/index.html">latest release</a> confirms that StreetView has yet to drive my street. For that I am happy.</p>

<p><strong>FOSS4G</strong> - The conference doesn't happen until next September and already the buzz is building. I have had people that I know have yet to touch an open-source GIS tool ask me what I know about "that <a href="http://foss4g.org/static/index.html">conference</a> I'm hearing about in Denver."</p>

<p><strong>Silverlight</strong> - I can't think of a technology in recent years that has given me more of a feeling of ambivalence. It has great capability and the Esri Silverlight API team has done good work building on it (this piece addresses Silverlight, not the Esri API). I think it'll continue to be a fine technology for intranet development but I'll leave it there. I don't expect my work with it to wind down anytime soon so I'll keep blogging it as I think it's perfectly possible to be productive with Silverlight within certain parameters. <a href="http://techcrunch.com/2010/10/30/rip-silverlight-on-the-web/">The whole episode regarding its future</a> (which was something of a tempest in a teapot, in reality) simply highlights the risks involved in relying on closed, proprietary technologies. This time, it was Silverlight, but make no mistake, the same risks are there with Flex/Flash (it just runs on more browser/OS combinations). Of course, there are risks with <em>any</em> technology choice but it's nice when those risks do not include "whim."</p>

<p>So that's it for my odds and ends. It's good to get them stuffed back into the couch. 2010 has been an interesting year. It almost feels like a year in which groundwork is being laid. It may just be me, but I have a feeling of anticipation similar to what I feel right before the first daffodils appear in Spring. It just feels like there's a good bit of pent-up energy and that a lot of new things are about to spring forth. It could be loads of fun.</p>
]]></content>
  </entry>
  
</feed>
