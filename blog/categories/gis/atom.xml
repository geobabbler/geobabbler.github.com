<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: GIS | geoMusings]]></title>
  <link href="http://blog.geomusings.com/blog/categories/gis/atom.xml" rel="self"/>
  <link href="http://blog.geomusings.com/"/>
  <updated>2014-07-16T13:42:57-04:00</updated>
  <id>http://blog.geomusings.com/</id>
  <author>
    <name><![CDATA[Bill Dollins]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[The Esri UC So Far #EsriUC]]></title>
    <link href="http://blog.geomusings.com/2014/07/16/the-esri-uc-so-far/"/>
    <updated>2014-07-16T12:13:00-04:00</updated>
    <id>http://blog.geomusings.com/2014/07/16/the-esri-uc-so-far</id>
    <content type="html"><![CDATA[<p>So I'm halfway through the largest geospatial event of the year, attending it for the first time in four years, and I haven't blogged yet. As always, it's a busy week. Because this event draws people from all over the country (and world), my dance card fills up pretty quickly. And, by the way, there's a conference going on.</p>

<p style="text-align:center;"> <img src="http://blog.geomusings.com/images/posts/plenary_stage.jpg" /></p>

<p>This is the first I've ever attended the Esri User Conference as just an attendee. If it were a video game, I'd be playing it on the easy level. I sat through the entire plenary for the first time in years. It was nice table setting for the rest of the week. As the father of a dancer, I have developed an eye for choreography and there is plenty of it up on the plenary stage. If I were to level one piece of constructive criticism toward the UC, it's that I'd let speakers be themselves a little bit more. That said, the content was delivered smoothly, which really the larger point.</p>

<!--more-->


<p>The plenary features a lot of demos that are rehearsed to within an inch of their lives. Knowing that, I still found ArcGIS Pro to be interesting. The UI is well-designed to get out the user's way and it's native 64-bit architecture finally allows it to take advantage of system resources in a way that ArcMap never could. The UI is more modern, featuring the ribbon toolbar. Esri seems to have learned a lesson from Microsoft by not re-engineering the UI of a familiar product, but releasing a new product that users can transition to. That was smart. In Microsoft Office terms, the UI upates from the Office 97 feel of ArcMap to more of an Office 2012 feel. Tasks in ArcGIS simplify geoprocessing even more but also run the risk of hiding complexity too much. I hope we're not training another generation of button-clickers.</p>

<p>One of the more subtle announcements in the plenary was that ArcGIS Portal will be included with ArcGIS Server at 10.3. I suspect that's the beginning of a gentle nudge of Server into ArcIMS-like oblivion but that's just my speculation.</p>

<p>The newly-released (not beta) ArcGIS Open Data extension (product?) was shown by <a href="http://twitter.com/ajturner">Andrew Turner</a>. It does a very nice job of putting an almost-GeoCommons-easy interface in front of ArcGIS Online to enable organziations to easily share their data. Andrew showed the implementations for the DC government and the State of Maryland. Maryland, in particular, is exceedingly happy with how quickly it has helped them start sharing data. By chance, I had dinner with some of the development team the night before and it's a motivated team with a diverse skill set not rooted in traditional Esri thinking which, in my opinion, bodes well for what they are doing.</p>

<p>Yesterday, I sat through a couple of sessions on the GeoEvent Processor (GEP), which has already been rebranded as the GeoEvent Extension for Server (or something like that). Those who have tracked my blog over the years know that I've done a lot of work with situational awareness systems. Within that field, I've concentrated a lot on feeds (streaming data sources) and track management so it's something of a geeky passion for me. Esri's previous, long-standing, and wholly awful product in this space was Tracking Server. I would gleefully dance around Tracking Server's funeral pyre.</p>

<p>GEP seems to be a better attempt at solving this problem. In its current incarnation, it simply doesn't have the throughput my customers will need (it currently supports about 800 - 1000 messages per second). To the product team's credit, they know this and are focusing on it. At 10.3, GEP will support "clustering" to increase throughtput. Clustering, however, was not explained during the session and could mean anything so I'll wait and see. The management interfaces and APIs behind GEP are top-notch and enable some of the use cases I've supported in the past. Once the throughput challenges are solved, this could be a product to watch.</p>

<p>You may have noticed a few parenthetical comments above when referring to product names. The reason for that is that Esri's product naming has fallen off the cliff to become just confusing, unwieldy, and random. Couple that with the fact that product names change constantly, or are recycled endlessly (Explorer?), and it's a complete mess. It's always been difficult walking new users through the maze of Esri products and the current naming "convention" doesn't help at all. Esri really needs to circle the wagons on this and simplify things.</p>

<p>That sums up my week so far. I'll try to check in again before I go.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Gearing Up For the Esri UC]]></title>
    <link href="http://blog.geomusings.com/2014/07/09/gearing-up-for-the-esri-uc/"/>
    <updated>2014-07-09T16:05:00-04:00</updated>
    <id>http://blog.geomusings.com/2014/07/09/gearing-up-for-the-esri-uc</id>
    <content type="html"><![CDATA[<p>With a house move behind us and a lot of unpacking and other tasks ahead, I am nonetheless getting ready to head out to the <a href="http://www.esri.com/events/user-conference">Esri International User Conference</a> next week. This will be my first time attending since 2010 and is the first UC since then that has aligned with my schedule in a way that I can make it. Of course, the price is right this year as well ($0.00).</p>

<p style="text-align:center;"> <img src="http://blog.geomusings.com/images/posts/office_view.png" /></p>

<p>The "big" UC has steadily dropped in significance for me over years as it has become much easier to get Esri-related information through various other channels; primarily through social media and local/regional events such as the <a href="http://www.esri.com/events/federal">FedUC</a> and local dev meetups. The last few trips to San Diego left me feeling that the content presented there is getting increasingly superficial compared to the other events. This year, however, I have been in the midst of building a house and moving so I have not had the time to attend the smaller events. As a result the UC makes sense. I am hoping the recent trend reverses itself.</p>

<p>I still do some Esri-based consulting so it's important to stay current however I can. My government customers are starting to at least ask about ArcGIS Online, so I want to finally get my mind around it as best I can. The messaging around that platform has been so muddled that it's still difficult for me to articulate what productivity advantages, if any, it actually offers. My own experimentation with it has left me wanting. The fact that it has been <a href="http://www.executivegov.com/2014/06/agriculture-dept-grants-fisma-certification-to-esri-cloud-mapping-tech/">certified as FISMA compliant</a> will certainly raise its profile with some of my Federal customers, though that's typically only the first step in a very long process. I'm also curious about ArcGIS Pro.</p>

<p>Unlike previous years, I won't be manning a booth (we sold ours a few years ago) or directly representing a customer so I'll actually have the luxury to attend sessions and meet up with people. There are some people who, unfortunately, I really only see face-to-face at such large magnet events so I'm looking forward to catching up with them, as well as meeting new people. I will, however, be popping into the paper session of one of my co-workers. (It would be awesome if the online agenda provided permalinks to individual sessions.)</p>

<p>So, if you're going to be in at the UC next week and would like to meet up, feel free to ping me on Twitter (<a href="https://twitter.com/billdollins">@billdollins</a>), via e-mail (bill [at] geomusings [dot] com), or drop a comment below.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Where Ya Been?]]></title>
    <link href="http://blog.geomusings.com/2014/06/20/where-ya-been/"/>
    <updated>2014-06-20T10:14:00-04:00</updated>
    <id>http://blog.geomusings.com/2014/06/20/where-ya-been</id>
    <content type="html"><![CDATA[<p>It's been rather quiet on the blog for a while. Sometimes the posts have to take a back seat to work and other things. This time of year tends to be busy anyway due to the end of the school year and its related activities, but this year has also included one move, construction of a house, and preparations for a second (final) move. In December we sold our house, which I had lived in for nearly 40 years, and moved into temporary quarters while the next house was being built. The sale of the old place was a pretty smooth experience as all of us, especially me, were ready for a change.</p>

<p style="text-align:center;"> <img src="http://blog.geomusings.com/images/posts/sunrise_crop_small.jpg" /></p>

<p>As a result, the experimentation and small projects which have driven the content of this blog since it started simply had to stop for a while. That's not to say that there has been no activity. I have posted over the last few months related to some mapping work and the "software exhaust" that has resulted from it. It's not really been possible, however, to sit down a create a well-structured discussion of those activies in the way that I would prefer, so I simply haven't.</p>

<!--more-->


<p>Because that work involved the use of <a href="https://www.mapbox.com/foundations/an-open-platform/#mbtiles">MBTiles</a>, it got me a little closer to some of the open-source tools produced by <a href="http://mapbox.com">MapBox</a> in a way that I haven't really needed to before. In addition to <a href="https://github.com/mapbox/mbutil">MBUtil</a> and <a href="https://www.mapbox.com/tilemill/">TileMill</a>, I've been able to use some of their <a href="http://leafletjs.com/">Leaflet</a> Javascript plug-ins for use in data visualiztion. My overall observation is that I've been very impressed with the quality of the tools they are putting out in terms of performance, stability, and elegance. It's been a pleasant experience working with their tools and I've also learned a lot by digging into their source.</p>

<p>It reminds me a lot of the experience I had a few years ago working with the GeoIQ tool set. That tool set resonated with me for the same reasons that the MapBox tool set does now; I feel like the authors of the tools think about problems and approach them in a manner similar to the way I do. As a result, I find the tools comfortable and not something I feel like I am fighting with. I'm not certain that this psychological aspect of software is given much attention but software is really a representation of the author's approach to problem-solving. For me, developing proficiency with a piece of software is establishing a connection with its author in a manner similar to that which is established with the author of a good book. It's one of the reasons I consider releasing open-source code to be such a brave thing.</p>

<p>It's my hope that I'll find ways to keep working with the MapBox tool set more, but such considerations are always driven by project availability and customer demand. In the meantime, there's a move to complete, a new house to settle into, and a summer to enjoy.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Personal Geospatial Workflows, May 2014 Edition]]></title>
    <link href="http://blog.geomusings.com/2014/05/20/personal-geospatial-workflows/"/>
    <updated>2014-05-20T08:21:00-04:00</updated>
    <id>http://blog.geomusings.com/2014/05/20/personal-geospatial-workflows</id>
    <content type="html"><![CDATA[<p>I have been spending the past few weeks dealing more with data and mapping than I have in quite a while. It's given me a chance to regain my footing with map-making, reconnect with some end-user tools like <a href="http://www.arc2earth.com">Arc2Earth</a>, and build a little more proficiency with things like <a href="http://www.gdal.org/">GDAL</a>, <a href="http://qgis.org">QGIS</a>, and <a href="https://www.mapbox.com/tilemill/">TileMill</a>. Of course, I've been able to sneak in some coding as I've identified gaps in my workflow.</p>

<p>In a nutshell, I am building base maps for use on disconnected mobile devices. There are two styles of base maps; imagery (really more of an imagery/vector hybrid) and a high-contrast map for use on the outdoor devices and sourced only from vector data. In both cases, I am building MBTiles databases to support the requirement for disconnected operations and to provide consistency in data size and performance.</p>

<p>For the imagery base maps, I was faced with following a data request process that may or may not have resulted in getting imagery in a timely fashion. Alternatively, I was presented with the option of using a tiled map service to get the imagery. Given that I was just making basemaps, this would have been acceptable but for the spotty speed and reliability of the network connection. The ideal solution would be to get only the tiles I need, store them locally, create a geo-referenced image from them, and build a virtual raster table (VRT) for each level.</p>

<!--more-->


<p>Downloading the tiles was easy, but for the VRT to work, each tile needed to be geo-referenced. It was fairly easy to modify the venerable <a href="http://www.maptiler.org/google-maps-coordinates-tile-bounds-projection/globalmaptiles.py">globalmaptiles.py</a> to include a routine to create world file parameters for a specified tile. With this, I was able to write out an affine transformation world file for each tile I downloaded. I rolled this whole process up into a <a href="https://github.com/geobabbler/tile-grab">Python script that's available here</a>. Please note that my goal was to create a VRT, so the script flattens out the tiling scheme so that all images are under the appropriate "Z" directory. (This particular server was an ArcGIS Server but the script doesn't care as long as you can provide a valide URL template.)</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bat'><span class='line'>python tile_grab.py -b <span class="m">-158</span>;<span class="m">21</span>;<span class="m">-157</span>;<span class="m">22</span> -d E:\tiles\oahu_img\a -i false -z <span class="m">6</span> -u http:<span class="n">//www.someserver.net/arcgis/rest/services/ImagerySvc/MapServer/tile/{z}/{y}/{x}.png</span>
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>With the tiles downloaded and geo-referenced, it was easy to use the gdalbuildvrt utility to generate the VRT, which can be used in QGIS, TileMill, and ArcGIS Desktop as you prefer.</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bat'><span class='line'>gdalbuildvrt <span class="m">6</span>.vrt <span class="m">6</span><span class="n">/*.png</span>
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>It seems a little odd to use tiles to make tiles, but I needed to add some additional data and styling to make the maps do what I needed to do. The downloaded tiles were just a stand-in for what would have been a standard raster data source. The range of useful resolution for a set of tiles is pretty narrow so you'll probably need to grab a few levels and, even then, you'll need to be careful how you use them. In most cases, using local raster/imagery is better but using tiles was fine for my use case and helped mitigate a byzantine data acquisition process. Here's how I set the ranges in ArcGIS (left) and TileMill (right):</p>

<p style="text-align:center;"> <img src="http://blog.geomusings.com/images/posts/vrt_zoom2.png" /></p>

<p>Using this approach, I was able to successfully generate my maps using either of two technology mixes. I succeeded in using both TileMill and ArcGIS/Arc2Earth to generate my maps. I ended up doing most of the work in Arc2Earth due to the availability of command-line tools that helped me optimize performance.</p>

<p>Before attempting this method, it's important to make sure that you are not violating any terms of service, license agreements, or attribution requirements in doing so. I knew this wasn't an issue in my case, but such questions need to be answered before you start grabbing data.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using Virtual Rasters to Generate Contours in QGIS]]></title>
    <link href="http://blog.geomusings.com/2014/04/17/using-virtual-rasters-to-generate-contours-in-qgis/"/>
    <updated>2014-04-17T13:39:00-04:00</updated>
    <id>http://blog.geomusings.com/2014/04/17/using-virtual-rasters-to-generate-contours-in-qgis</id>
    <content type="html"><![CDATA[<p>Every now and again, I am asked to make maps. It's not my strongest suit, but it sometimes comes with the territory. My latest task, as mentioned in my previous post, involves building support for <a href="https://www.mapbox.com/developers/mbtiles/">MBTiles</a> databases into a mobile situational awareness tool. This is done so that the devices can have a persistent local basemap in the field. The need arose to ensure that the basemaps were high contrast to assist with visibility in bright sunlight. Something like this:</p>

<p style="text-align:center;"> <img src="http://blog.geomusings.com/images/posts/qgis_contour0.png" /></p>

<p>One of the requirements was to have topographic-map-like contours to indicate changes in elevation. Existing map services didn't provide what we needed so it was necessary to build a custom map, which meant generating contour lines. It had been years since I had last done that with Esri tools, but I didn't have any extension licenses available, so I turned to <a href="http://www.qgis.org/en/site/">QGIS</a> to get the job done this time.</p>

<!--more-->


<p>My area of interest was a portion of Virginia. Since I couldn't find any pre-generated contours for the state, I turned to elevation models. There are numerous places to get such data, but I <a href="http://geoserve.asp.radford.edu/dems/va_dems.htm">downloaded some DEMs from Radford University</a> since they are already carved up by county. They are perhaps a bit dated, but they sufficed for this particular testing round.</p>

<p>It was easy to find <a href="http://boringnerdystuff.wordpress.com/2012/07/14/302/">guidance on how to generate contours in QGIS</a>. So I ran the process on a couple of adjacent counties and noticed that the edges didn't line up, which was not surprising. My first thought was that I would need to merge the DEMs but, luckily, I stumbled across the virtual raster tool in QGIS. This tool provides a nice UI for building a <a href="http://www.gdal.org/gdal_vrttut.html">GDAL virtual raster</a> from a series of separate rasters specified by the user. This can be a bit cumbersome to do manually and this GUI tool was a real time saver. It can be found in QGIS Dufour here:</p>

<p style="text-align:center;"> <img src="http://blog.geomusings.com/images/posts/qgis_contour1.png" /></p>

<p>To make my life easier, I moved all of my DEMs into one folder so I could just point the tool at the folder. I filled in the name of the output file and took the defaults for everything else.</p>

<p style="text-align:center;"> <img src="http://blog.geomusings.com/images/posts/qgis_contour2.png" /></p>

<p>Notice that the dialog shows me the GDAL command that I am building with the UI. Advanced users can even edit it here. This is a really nice feature that can help you get comfortable with GDAL. I am not a GDAL expert, nor am I particularly adept with raster operations so I found this to be a huge help and I plan to use it more.</p>

<p>The tool doesn't change any data; it merely writes a text file so it works very quickly. The resulting virtual raster was done in a few seconds.</p>

<p style="text-align:center;"> <img src="http://blog.geomusings.com/images/posts/qgis_contour3.png" /></p>

<p>With the data now "merged," I was able to continue with data generation. For my purposes, 10-meter contours were more than sufficient. I generated a shapefile, but any QGIS-supported format is valid as an output. It should be noted that the "Attribute name" choice is not checked by default. Check this if you want to attach the elevation value to each line. Also notice that QGIS is again giving us the relevant GDAL command as we build it. This is very powerful as it gives you the option to use QGIS to prototype GDAL operations and then script them outside of QGIS, if you desire.</p>

<p style="text-align:center;"> <img src="http://blog.geomusings.com/images/posts/qgis_contour6.png" /></p>

<p>This process took a little longer, thanks to Fauquier County, but still finished in about 90 seconds. The resulting contours were contiguous across counties, so my needs were met.</p>

<p style="text-align:center;"> <img src="http://blog.geomusings.com/images/posts/qgis_contour8.png" /></p>

<p>I'm now in the process of styling the map in <a href="https://www.mapbox.com/tilemill/">TileMill</a> so that I can generate the databases. It's good to occasionally take off my developer hat and put on that of a user. I've known for quite a while that QGIS stands toe-to-toe with any other desktop GIS software but this work got me to use some tools that I rarely ever touch. I was impressed with not only the speed, but also how smoothly the work flowed. My pedestrian laptop didn't engage in nearly the same level of huffing and puffing that it does when I have to use other software. That may be a hidden "win" in that users can extend the useful life of their hardware by using tools that don't tax it as much while producing the same results.</p>
]]></content>
  </entry>
  
</feed>
