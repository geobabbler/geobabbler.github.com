<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: GIS | geoMusings]]></title>
  <link href="http://blog.geomusings.com/blog/categories/gis/atom.xml" rel="self"/>
  <link href="http://blog.geomusings.com/"/>
  <updated>2014-02-13T17:32:29-05:00</updated>
  <id>http://blog.geomusings.com/</id>
  <author>
    <name><![CDATA[Bill Dollins]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Initial Thoughts On the DC DevSummit]]></title>
    <link href="http://blog.geomusings.com/2014/02/13/initial-thoughts-on-the-dc-devsummit/"/>
    <updated>2014-02-13T17:19:00-05:00</updated>
    <id>http://blog.geomusings.com/2014/02/13/initial-thoughts-on-the-dc-devsummit</id>
    <content type="html"><![CDATA[<p>This week, I attended the first-ever <a href="http://www.esri.com">Esri</a> <a href="http://www.esri.com/events/devsummit-dc">DC DevSummit</a> which followed the <a href="http://www.esri.com/events/federal">Federal GIS Conference</a> (please switch it back to "FedUC"). This event, intended and a smaller, Federally-focused, companion to the annual Palm Springs DevSummit, came together quickly but was very well-attended with about 300 attendees.</p>

<p style="text-align:center;"> <img src="http://blog.geomusings.com/images/posts/devsummit.jpg" /></p>

<p>It was interesting to note that the most well-attended sessions of the day had to do with Javascript (every Javascript session had over 100 participants). As more and more organizations update their IT infrastructures, the acceleration away from plug-ins seems to be picking up pace. The most common refrain amongst attendees in that regard is that continued standardization on IE8 remains the biggest impediment to sunsetting things like Flex and Silverlight, but the logjam seems to be starting to break loose.</p>

<!--more-->


<p>Despite the photo I posted, <a href="http://twitter.com/ajturner">Andrew Turner's</a> open-source session was fairly well-attended. It was good to see tools like <a href="https://github.com/Esri/koop">Koop</a> in action. It is clear that there is real effort going on within Esri to produce open-source tools and that the people working on them are genuinely committed to them. That said, it is obviously still early days and such efforts are clearly swimming upstream against the preponderance of corporate culture. This is an effort that will best be judged over the long haul.</p>

<p>I also have to give a shout out to <a href="http://twitter.com/agup">Andy Gup</a>, whom I finally met at this conference. By chance, I sat through three of his sessions. He is one of the best technical presenters I have ever seen and Esri should require junior staff to sit through his sessions to see how it should be done.</p>

<p>I found the DevSummit generally worthwhile and I was impressed with how well it came together given the short timeframe. Since I was encouraged to blog suggestions, here are a few:</p>

<ol>
<li><p>Make a DevSummit a permanent fixture as a follow-on to the Federal User Conference each year. The format of this year's Federal conference can be tweaked but stay mainly focused on user-centric use cases and some intro-level discussions of technologies. A DevSummit would mark a shift in to much more technical content with advanced discussions of APIs, security, techniques and best practices.</p></li>
<li><p>Pull out the stops. As I indicated in item 1, ramp up the technical content, in comparison to that of the Federal conference, significantly. This year's event started down that path. I would keep the technical content of the Federal conference on the bunny slopes and shift to the black diamonds for the DevSummit.</p></li>
<li><p>Expand to two days. It was a quick day and there were definitely sessions I would have liked to have gotten to. Additionally, it would be good to see some user content, maybe some lightning talks on the evening between the days. One of the biggest challenges working in the Federal space is the compartmentalization between and within agencies. With the DevSummit drawing interested people to one location, it would be good to get more opportunities to interact with other developers and exchange information.</p></li>
<li><p><a href="http://www.gsa.gov/portal/category/102371?utm_source=OCM&amp;utm_medium=print-radio&amp;utm_term=HP_13_SpecialTopics_fedramp&amp;utm_campaign=shortcuts">FedRAMP</a> and <a href="http://en.wikipedia.org/wiki/Federal_Information_Security_Management_Act_of_2002">FISMA</a> were non-existent this year. Jim Barry explained to me that these were areas where content simply wasn't ready to go in the short time given to prepare for the DevSummit. That's fair, and I certainly respect the decision to not provide content that could not be done well. These are, however, core issues for anyone doing development for the Federal Government. Next year's DC DevSummit really needs to have content for developers attempting to deploy to FedRAMP and achieve FISMA compliance with Esri tools.</p></li>
</ol>


<p>Those my quick hits. I'll probably have more after I have time to digest what I saw and dig out from the backlog resulting from two days out of the office. Kudos to <a href="http://twitter.com/jimbarry">Jim Barry</a> for his work pulling the DC DevSummit together.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Meanwhile, Over at Zekiah...]]></title>
    <link href="http://blog.geomusings.com/2014/02/06/meanwhile/"/>
    <updated>2014-02-06T11:34:00-05:00</updated>
    <id>http://blog.geomusings.com/2014/02/06/meanwhile</id>
    <content type="html"><![CDATA[<p>I don't usually cross-pollinate between this, my personal blog, and the company blog over at <a href="http://www.zekiah.com">Zekiah</a>. One of the great things about working at a place like Zekiah, however, is the opportunity to work with smart people and see what they are doing. At times, my colleagues will share components of their work on the company blog. We encourage this, and the experimentation that leads to the posts, as a way to keep our technical capabilities fresh and to also showcase what we do in a way that goes beyond the typical capabilities statements that exist on every site. My colleagues have been pretty busy but have managed to take some time to write a few posts about their work:</p>

<ul>
<li><a href="http://www.zekiah.com/index.php?q=blog/2014/02/04/esri-cityengine-unity-40-and-oculus-rift">Esri CityEngine, Unity 4.0 and the Oculus Rift</a> - My colleague, <a href="http://twitter.com/DanEntzian">Dan Entzian</a>, is an avid gamer, a great developer, and a smart GIS guy. This post combines those interests by showing how to bring cities created in Esri's <a href="http://www.esri.com/software/cityengine/">CityEngine</a> into gaming environments like <a href="http://unity3d.com/">Unity</a> and integrate them with the <a href="http://www.oculusvr.com/">Oculus Rift</a> virtual reality display. It's a quick, but detailed, read that shows the interactions possible between geospatial tools and games.</li>
</ul>


<!--more-->


<p style="text-align:center;"> <img src="http://blog.geomusings.com/images/posts/unity_ide.png" /></p>

<ul>
<li><p><a href="http://www.zekiah.com/index.php?q=blog/2014/01/23/using-awk-ease-your-csv-manipulation">Using AWK to ease your CSV manipulation</a> - <a href="http://twitter.com/hugoestr">Hugo Estrada</a> shows how to use an old, but still effective, tool, <a href="http://www.grymoire.com/Unix/Awk.html">AWK</a>, to process GPS data for use in GIS software. This post is a great reminder that the best tool for the job may already be sitting there at our command prompt waiting for us.</p></li>
<li><p><a href="http://www.zekiah.com/index.php?q=blog/2013/12/18/exporting-esri-silverlight-graphic-layer-google-earth-part-2">Exporting ESRI Silverlight Graphic Layer to Google Earth, Part 2</a> - While Silverlight is, politely speaking, passe, we have a few customers that are still attached to it. Generally, the systems that are using it are accredited systems of record so a rip-and-replace of Silverlight (or any other component) is simply not feasible without a significant paperwork drill. So we try to help our customers keep those systems as useful for their end users as possible. This post, also by Dan Entzian, illustrates how we did that in one case. A follow up to <a href="http://www.zekiah.com/index.php?q=blog/2011/10/11/exporting-esri-silverlight-graphic-layer-google-earth">an older post</a>, this post was done in response to an e-mail inquiry from a reader of the previous post.</p></li>
<li><p><a href="http://www.zekiah.com/index.php?q=blog/2013/12/17/overview-clojure">An Overview of Clojure</a> - In this post, Hugo Estrada takes a look a <a href="http://clojure.org/">Clojure</a>, a variant of the Lisp programming language, and reports on his experience at Clojure Con. I found this particularly interesting since, as a lifelong programmer, I am always interested in new languages (even if it is getting harder to find the time to tinker with them myself).</p></li>
<li><p><a href="http://www.zekiah.com/index.php?q=blog/2014/01/02/generating-physical-schemas-pim">Generating Physical Schemas From a PIM</a> - Okay, this one was written by me, but the work is pretty interesting and involved the efforts of a few co-workers, including Barry Schimpf and Dan Entzian. This post describes a tool that we developed as part of our overall approach to geospatial data model management. This script generator produces SQL scripts for either <a href="http://postgis.net/">PostGIS</a> or <a href="http://www.gaia-gis.it/gaia-sins/">SpatiaLite</a> that enable a user to create spatial databases that are compliant with a data model. The information for the data model (which is always user-defined, not proscribed by us) is stored in what we call the platform independent model, or <a href="http://www.zekiah.com/index.php?q=blog/topics/pim">PIM</a>. We've used the PIM, its encapsulating API, and tools to good effect for a couple of customers now. This post attempts to provide a concrete picture of what can be an abstract concept.</p></li>
</ul>


<p>Since Zekiah is a services company, rather than a platform company, we get to work with a broad range of technologies in support of our customers, in addition to our own internal research. This makes each day pretty interesting and can also make for lively conversation at company events. As the posts above showcase, my colleagues are working on some interesting things and it's a pleasure to work them each day.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Esri Federal GIS Conference Features Immersion Summits]]></title>
    <link href="http://blog.geomusings.com/2014/02/05/esri-federal-gis-conference-features-immersion-summits/"/>
    <updated>2014-02-05T20:19:00-05:00</updated>
    <id>http://blog.geomusings.com/2014/02/05/esri-federal-gis-conference-features-immersion-summits</id>
    <content type="html"><![CDATA[<p>The 2014 installment of the <a href="http://www.esri.com/events/federal">Esri Federal GIS Conference</a> (formerly known as the Federal User Conference) happens next week. I have attended the event off and on since its inception. While I originally was drawn by the presence of a large geo-related event in my local area, that gap has been filled by numerous, smaller events from various sources in the past few years. The FedUC has traditionally had something of an identity crisis, with the content often feeling a bit diffuse and somewhat rushed over its quick, two-day schedule.</p>

<p>To Esri's credit, and probably in recognition of the changing economics regarding travel for Federal employees, they have continued to fine-tune the event when they could have easily walked away from it. The main problem with the FedUC is the fact that the Federal Government performs a wide array of functions that are difficult to cover well over two days in a conventional format. Esri has tackled that problem this year with the introduction of <a href="http://www.esri.com/events/federal/agenda/immersion-summits">"immersion summits,"</a> which are three-and-a-half hour sessions dedicated to specific domain areas.</p>

<!--more-->


<p>For example, check out the Natural Resources Immersion Summit led by my friend <a href="http://twitter.com/jsteffenson">John Steffenson</a>. The agenda features speakers from USDA, USGS, the US Forest Service, the EPA, the Fish and Wildlife Service, and Department of Interior, representing over 100 years of higher education dedicated to natural resources management. The session also has slots for several demos of systems deployed in natual resources domain.</p>

<p>The session's content seems to be designed take a holistic view, including fiscal, logistical, technical, and demographic challenges among others. This type of deep focus is an intriguing change to event's focus. While nautral resources is not my usual domain, I do like to drop into other sessions as I find that uses cases from other domains can give me ideas to bring back to my work. I think this new format could maximize the use of the compact schedule of the Federal GIS Conference and begin to give the event its own identity.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[File Geodatabase Schema Compare Tool]]></title>
    <link href="http://blog.geomusings.com/2014/01/08/file-geodatabase-compare-tool/"/>
    <updated>2014-01-08T20:32:00-05:00</updated>
    <id>http://blog.geomusings.com/2014/01/08/file-geodatabase-compare-tool</id>
    <content type="html"><![CDATA[<p>In my work supporting various aspects of geospatial data modeling, I've spent a lot of time delving into concepts around configuration management of such data models. We've been able to apply a core tool set to perform various functions such as version managment, profiling, version-to-version migration, and validation in conjunction with a system we call the platform independent model (PIM). I gave quick overview of the PIM <a href="http://www.zekiah.com/index.php?q=blog/2014/01/02/generating-physical-schemas-pim">in this post over on the Zekiah blog</a> and the complete series on it <a href="http://www.zekiah.com/index.php?q=blog/topics/pim">can be found here</a>.</p>

<p>I've recently spent a bit of time consolidating code after a recent data delivery and decided to post a utility that was an outgrowth of that effort: <a href="https://github.com/Zekiah/ArcGISCompare">a tool to compare schemas of two Esri file geodatabases and report differences</a>. This lent itself to general use because it does not require any connection to a PIM.</p>

<p style="text-align:center;"><img src="https://github.com/Zekiah/ArcGISCompare/raw/master/screenshot.png" /></p>

<!--more-->


<p>The PIM deals mainly at the logical level with data models, but a full configuration management workflow must occasionally touch physical data sets. One use case we had to support, for which this tool was built, was the case where users in the field must compare separate data sets for eventual integration. Although these workflows start with a template data set, it is not unusal for changes to be made during collection, resulting in very similar but not identical schemas. This tool helps users identify such differences in order to make configuration management decisions based upon the actual state of the collected data.</p>

<p>The tool is fairly straightforward: choose a template data set, choose an implementation data set, run the compare, and examine the results. It contains ArcObjects dependencies although we may migrate it to the file geodatabase API in order to eliminate those.</p>

<p>We are also in the process of building a similar tool to work with SQLite/SpatiaLite data sets, which is the other format we commonly see used and will post that tool when it is complete. In the meantime, I hope you find this application useful.</p>

<p>An installer (10.1) <a href="https://dl.dropboxusercontent.com/u/6749645/PIM/setup_ArcGISCompare.zip">can be found here</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Of Predictions and (Geo)Hipsters]]></title>
    <link href="http://blog.geomusings.com/2014/01/07/predictions/"/>
    <updated>2014-01-07T20:09:00-05:00</updated>
    <id>http://blog.geomusings.com/2014/01/07/predictions</id>
    <content type="html"><![CDATA[<p>"Never make predictions, especially about the future." - Casey Stengel</p>

<p>A few days ago, my friend <a href="http://www.linkedin.com/profile/view?id=8637855">Atanas Entchev</a> asked me for <a href="http://geohipster.com/2013/12/31/what-will-be-hot-in-geo-in-2014-predictions-from-the-geohipster-crowd/">my thoughts on coming trends in 2014</a> for a feature he was preparing for his <a href="http://geohipster.com/">GeoHipster</a> site. Being the obliging sort that I am, I provided a couple and I've been attempting to explain one ever since. This has mostly been back-channel via private messages and such but, today, the GeoHipster piece was the subject of the "#geowebchat" on Twitter. Twitter is very effective for some types of communication but quickly goes off the rails where nuance or anything long-form is required. So, it was time for a post. My prediction went like this:</p>

<blockquote><p>I think 2014 will be the year Javascript takes over mapping and visualization in the geospatial world.</p></blockquote>

<p>It was followed by an apparently too brief explanation that I will attempt to expand here.</p>

<!--more-->


<p>I am very fortunate that, in my professional circle, I am connected to a number of people who are doing very cutting-edge things with a lot of technologies. These people have been doing very impressive things with various web technologies for a number of years. So much so that these technologies are somewhat mundane in those circles. As a person who makes my living supporting Federal contracts for a number of agencies, I also have a foot in another camp that has not been as far along with these tools.</p>

<p>Before I get too far into this, I will state that there are many people building very cutting-edge systems in and for the Federal government, but the penetration of modern web tools and techniques is very uneven for a number of reasons. The reasons range from procurement inefficiencies to byzantine information security requirements to workforce training issues and so on. This is generally a reflection of process, not people. As a result, there are still many shops operating on platforms such as Windows XP and Internet Explorer 8, which does not allow for advanced web development.</p>

<p>My observation over on GeoHipster was not targeted at the cutting-edge developers but rather a reflection of changing trends I am seeing across the vast middle of the technology sector represented by large teams of developers working in the bullpens of various government buildings and large system integrators. Initiatives are under way to begin swapping out antiquated technologies for more modern, if still slightly behind the curve, versions that allow for more modern approaches. These initiatives happen to coincide with a push by major vendors away from older technologies, such as browser plug-ins, to more standard development tools such as Javascript, and its supporting ecosystem.</p>

<p>This community is made up of a vast number of very talented developers who have been working with middle of the road technologies for all of the reasons discussed above. The maturation of tools and processes in the Javascript ecosystem lends itself to wider adoption going forward and I see that accelerating in 2014. Dave Bouwman's <a href="http://blog.davebouwman.com/2014/01/04/javascript-fu/">excellent post on Javascript tools</a> is exactly the kind of resource that shows developers used to working with heavy IDEs and other tools that provide a lot of hand-holding how to achieve the productivity they expect with the next generation of development tools. Dave, of course, is also well-versed is the life these developers lead so I am certain he had an eye on that community with his post.</p>

<p>All of this leads to great opportunity. For as much great work that has already been done, there is an army of smart, talented developers who have yet to be turned loose with modern web tools. This is a community that implemented geofencing, "geotriggers," location-based alerting and other concepts using older languages and architectures at least a decade before they appeared in the current marketplace.</p>

<p>So, ultimately, my prediction had very little to do with Javascript and modern web technologies and much more to do with the talents of a large developer community that has been waiting to make use of them. Overly optimistic? Perhaps, but it beats the alternative.</p>
]]></content>
  </entry>
  
</feed>
