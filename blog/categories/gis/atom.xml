<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: GIS | geoMusings]]></title>
  <link href="http://blog.geomusings.com/blog/categories/gis/atom.xml" rel="self"/>
  <link href="http://blog.geomusings.com/"/>
  <updated>2013-12-27T09:20:38-05:00</updated>
  <id>http://blog.geomusings.com/</id>
  <author>
    <name><![CDATA[Bill Dollins]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[JS.Geo 2014 Announced]]></title>
    <link href="http://blog.geomusings.com/2013/12/27/js-dot-geo-2014-announced/"/>
    <updated>2013-12-27T08:29:00-05:00</updated>
    <id>http://blog.geomusings.com/2013/12/27/js-dot-geo-2014-announced</id>
    <content type="html"><![CDATA[<p>Information about the follow-up to last year's <a href="http://www.jsgeo.org/">JS.Geo</a> event has been percolating back-channel for a few weeks now. Now some <a href="http://lanyrd.com/2014/jsgeo14/">official details have been posted</a>. This year's event will be held in April in San Francisco. I attended last year's session, really liked the focused format, and got a lot of good information out of it. One thing that was nice was that, regardless of whether you are of an Esri or open-source persuasion in your development preferences, there was a lot of good information presented with a relative lack of hyperbole, which made it easy to focus on the content.</p>

<p style="text-align:center;"><img src="http://blog.geomusings.com/images/posts/jsgeo13.png" /></p>

<p>As <a href="http://twitter.com/geo_rube">Todd Barr</a> <a href="http://drunkengeographer.tumblr.com/post/69908102132/when-i-realize-that-no-one-who-plans-gis-spatial">eloquently points out</a>, the April 2014 calender is somewhat crowded with geo-events but, based on last year's event, I'd recommend putting JS.Geo at the top of the list.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Consider the 'Alternative']]></title>
    <link href="http://blog.geomusings.com/2013/11/27/consider-the-alternative/"/>
    <updated>2013-11-27T13:01:00-05:00</updated>
    <id>http://blog.geomusings.com/2013/11/27/consider-the-alternative</id>
    <content type="html"><![CDATA[<p>When I was in college, I had a psychology professor who posited that you could train a cat (a dodgy proposition at best) to take a circuitous route to its food bowl by only rewarding that behavior. He was clearly a behaviorist and was convinced that you could completely condition the instinct to go straight to the food bowl out of the cat. To my knowledge, this professor did not own a cat and never attempted to test his assertion.</p>

<p>I was reminded of this after reading my friend Atanas Entchev's <a href="http://blog.entchev.com/2013/11/22/some-post-postgis-day-thoughts.aspx">post in reaction</a> to the <a href="http://postgis.net">PostGIS</a> Day <a href="http://www.spatiallyadjusted.com/2013/11/21/todays-hangout-postgis-day-extravaganza-panel/">hangout panel discussion</a>. In his post, <a href="http://twiiter.com/atanas">Atanas</a> describes difficulty in convincing customers to consider open-source geospatial tools. These customers and prospects are comfortable with their proprietary tools and associated workflows and are reluctant to consider switching. I have encountered this attitude many times myself so I take no issue with the observation. Barriers to exit are real considerations, regardless of the new technology being considered. Organizations align themselves around their tools to achieve maximum efficiency with them. I discussed these issues at a talk I gave last year to the <a href="https://njgin.state.nj.us/OIT_NJGF/index.jsp">New Jersey Geospatial Forum</a> about how organizations can extend their existing geospatial technology investments with open-source technologies. These issues are very real for any organization with a mature, extended investment in a particular technology stack.</p>

<p>Atanas went on to liken the attitude to that with which some people view alternative medicine and I can see his point. Traditional GIS has set itself apart from the rest of the technology world for so long that users are generally conditioned to believe that GIS workflows should involve a series of <a href="http://en.wikipedia.org/wiki/Rube_Goldberg">Rube Goldberg</a> machinations involving file-based data sets, some proprietary scripting, and possibly some application-level business logic to relate and/or join data as necessary. This has taken various forms over the years but diagrams of those workflows tend to look the same.</p>

<p style="text-align:center;"><img src="http://blog.geomusings.com/images/posts/geo_model.png" /></p>

<!--more-->


<p>Standing in contrast to such things, PostGIS looks alien, or "alternative." In truth, it is not "alternative" but rather "standard." As an example, here is <a href="http://blog.geomusings.com/assets/demos/nbi/">a map I produced a few weeks ago</a> showing the average ages of bridges by county. (I am not a cartographer.) It is a simple aggregation of the <a href="http://www.fhwa.dot.gov/bridge/nbi.cfm">National Bridge Inventory</a>, which consists of tens of thousands of records by county (3100-ish records). All of the data processing was done in PostgreSQL/PostGIS using nothing more exotic than SQL aggregate functions and some joins. None of the operations took longer than 6 seconds on my very pedestrian laptop. When I was done, I used QGIS to play with visualization and then dump out the static GeoJSON for use in Leaflet.</p>

<p>For my many friends who are regular users of PostGIS, this is nothing exotic. For some of my friends who regularly use commercial tools, this is interesting but not earth-shattering. But for a large portion of my friends who are comfortable with traditional tools and workflows, the time-to-market for this effort (35 minutes from the time I downloaded the NBI to the time I pushed the map to GitHub) has them taking notice. This entire workflow involved SQL extended with OGC-compliant spatial objects. (Side note: I have been hard on OGC's web efforts but the Simple Features Specification has been a quiet workhorse across the geospatial industry for over a decade. It's a good example of the benefit that well-designed standards can provide.) The map is being served from static content over simple HTTP with some client-side Javascript handling visualization. No heavy APIs or middleware involved or needed. The QGIS part was really necessitated by own cartographic limitations, but I could have fully generated the GeoJSON from SQL as well.</p>

<p>This example is fairly simplistic but I have good friends that are using PostGIS, and nothing more, to perform analyses and produce results for decision makers while sitting in meetings. This type of turnaround is standard in other market segments and the geospatial industry should expect nothing less. It requires nothing more than a strong foundation in SQL, mastery of spatial processes, and detailed understanding of your own data.</p>

<p>So I have come to realize that the mainstream GIS community has become very much like my professor's theoretical cat; conditioned to take the long way to the end result when more direct paths are clearly available. What's more, they have become conditioned to think of such approaches as normal. Geospatial analytical operations can be very complex and the approaches to performing them were, in the past, necessarily convoluted due to the lack of understanding of spatial data types and operations within mainstream platforms. Those barriers have been rapidly disappearing over the past decade or so, but the user community has been slow to let go of its comfort with familiar tools and convoluted approaches. As I stated above, organizational barriers to exit are real considerations, but the inherent efficiencies available in modern geospatial tools such as PostGIS make the transition worth the effort.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[GIS Day After]]></title>
    <link href="http://blog.geomusings.com/2013/11/19/gis-day-after/"/>
    <updated>2013-11-19T09:13:00-05:00</updated>
    <id>http://blog.geomusings.com/2013/11/19/gis-day-after</id>
    <content type="html"><![CDATA[<p>It's the morning of November 21st, but not for long. You open one eye. Just one; it's best not to rush such things. Apparently, you finally came to rest in the ball pit you all made using the squishy globes from myriad conferences past. A cursory scan tells you the GIS lab is trashed. It starts to come back to you: the rousing game of "Pin the Certificate on the Khakis." Yes, there are your pleated khakis on the wall with everyone's training and GISP certificates stuck on or around them with pushpins. Someone won in what would have been a most painful way if the khakis had been on your body. The loin cloth fashioned from the old hard-copy topos (which you are still wearing). The fact that you let the intern talk you into finally opening a Twitter account and your glee at discovering you could attach photos to geocoded tweets with your BlackBerry.</p>

<p>You look around the room at your coworkers strewn across the floor. There's the ArcObjects guy still sporting his "war paint" from the plotter toner. There's your lead analyst with a face tattoo of the town's land-use drawn in marker and, she proudly insisted, accurately projected in state plane. Slowly, you are able to account for everyone on your GIS staff. Good, no one has gone missing...except the intern.</p>

<p>The door opens and you turn to see the intern standing there in all of her college-kid resilience, letting in far too much sunlight for your comfort. You're not sure it's possible to hate anyone more in this moment.</p>

<p>"Oh, good," she says, "you're awake. Are you going to do the hangout?"</p>

<p>"Hangout?" you mumble.</p>

<p>"Yeah, <a href="http://www.spatiallyadjusted.com/2013/11/18/postgis-day-special-hangout-this-week/">James Fee is doing a PostGIS Day hangout with a panel of experts on PostGIS</a>. I told you about this. I told you about <a href="http://postgis.net">PostGIS</a>. Don't you remember? It starts in about an hour."</p>

<p>It does sound familiar. You give it some thought. What better way to shake off the cobwebs from the bacchanalia of the "BEST GIS DAY EVAR!!!" (so says the hand-lettered Sharpie on the lab's wall) than a little geo-hair-of-the-dog? Maybe it's time to finally pay attention to this open-source stuff. You look around to survey the damage one more time. Besides, ditching the Oracle license might just about pay for this.</p>

<p>"Yeah," you reply, "I'll be there in five minutes. Close the door, please."</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Desktop Not Dead]]></title>
    <link href="http://blog.geomusings.com/2013/10/23/desktop-not-dead/"/>
    <updated>2013-10-23T09:42:00-04:00</updated>
    <id>http://blog.geomusings.com/2013/10/23/desktop-not-dead</id>
    <content type="html"><![CDATA[<p>In 2011, I gave a talk at the NCGIS conference about the continued dominance of the desktop in the world of GIS. In that talk, my main point was that, regardless of the ultimate destination of GIS data or maps (cloud, server, paper, PDF, etc.), most GIS data passes through a desktop GIS at some point. I don't have hard data to back up that claim but I think anyone who has worked in the industry for any length of time will agree that it feels right. If we loosely define "desktop GIS" to include not only GUI analytical tools like <a href="http://www.esri.com">ArcMap</a> or <a href="http://qgis.org">QGIS</a>, but also command-line tools such as <a href="http://www.gdal.org/">GDAL/OGR</a> and cartographic tools such as <a href="https://www.mapbox.com/tilemill/">TileMill</a>, I think the statement is even more comfortable.</p>

<p style="text-align:center;">{% youtube ljIQo1OHkTI %}</p>

<p>Essentially, my claim was that desktop GIS is still the onramp for most of the data we interact with on the web. Over the past few years, geographically tagged live and temporally-sensitive data streams have increased in importance but I think most geospatial data still starts as traditional data sources (rasters, vectors, terrain, etc.) that pass through a desktop for analysis, processing, and styling before moving on to the web. Esri, for example, still features its desktop tools as prominent parts of its web publishing workflow and <a href="http://boundlessgeo.com/">Boundless</a> is working on a <a href="https://github.com/boundlessgeo/suite-qgis-plugin">similar path for QGIS</a>.</p>

<!--more-->


<p>The announcement of a Google Maps Engine connector for both <a href="https://github.com/googlemaps/mapsengine-arcgis-connector">ArcGIS</a> and <a href="https://github.com/googlemaps/mapsengine-qgis-connector">QGIS</a> is yet another example of the continued importance of the desktop in the GIS world. Simply put, the chances of a user choosing your platform increases if you can cut to the front of the line and present yourself in their desktop environment. <a href="http://blogs.esri.com/esri/arcgis/2013/10/22/googles-arcgis-toolbar-for-the-cloud/">Andrew Turner did a nice summary of many such integration efforts</a> involving ArcGIS Desktop, although the post fails to mention <a href="http://www.arc2earth.com">Arc2Earth</a>, which I consider the most comprehensive extension of its kind on the market. His discussion tracks with my personal experience in recent years. My most public activities have been <a href="https://code.google.com/p/ziggis/">zigGIS</a>, the <a href="http://blog.dc.esri.com/2010/11/22/toolbars-for-geocommons-and-geoiq/">GeoCommons toolbars</a> (thanks for the mention, Andrew), and the <a href="http://www.weogeo.com">WeoGeo</a> toolbar. I've also built a couple of others for organizations that wanted to get their data products in front of ArcGIS users easily and I am currently working on a live feed extension for a government user. The reality is that I've done more desktop development in the last three years than I had done in the preceding ten.</p>

<p>Andrew's point at the end of his post about Esri's extensibility through various means is quite true. As much as developers love to complain about ArcGIS Desktop and ArcObjects (myself included), I have yet to find a data source that I couldn't integrate using those tools. As I dig into the APIs behind QGIS, I am finding the same to be true there. Despite the tendency to downplay desktop GIS tools these days, I see them continuing to play a significant, if quiet, role in defining how we interact with maps and geospatial data across all platforms for the foreseeable future.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[WeoGeo: Now With GeoJSON]]></title>
    <link href="http://blog.geomusings.com/2013/10/17/weogeo-now-with-geojson/"/>
    <updated>2013-10-17T05:42:00-04:00</updated>
    <id>http://blog.geomusings.com/2013/10/17/weogeo-now-with-geojson</id>
    <content type="html"><![CDATA[<p>It's great news that the <a href="http://www.washingtonpost.com/politics/house-effort-to-end-fiscal-crisis-collapses-leaving-senate-to-forge-last-minute-solution/2013/10/16/1e8bb150-364d-11e3-be86-6aeaa439845b_story.html?hpid=z1">government shutdown is finally over</a>. Many of our colleagues across the geospatial industry can now report back to work, ending a another stressful period for them. During the shutdown, many stepped up to try and fill the gap left by shuttered government web sites that would normally distribute geospatial data.</p>

<p>Among those who stepped into the breach are my friends at <a href="http://www.weogeo.com">WeoGeo</a>, who told me they saw a huge uptick in traffic as the community realized that government data sets such as TIGER and DRG are freely available in the <a href="http://market.weogeo.com/">WeoGeo Market</a>. One of the capabilities that has been quietly introduced into WeoGeo's platform over the last few days is the ability to extract and download TIGER and OSM data directly in <a href="http://geojson.org">GeoJSON</a> format. The embedded video by WeoGeo walks through the customization and ordering process better than I can, but it's great to have the ability to extract fine-tuned data sets directly in GeoJSON format for use in modern web-mapping tools.</p>

<iframe src="http://fast.wistia.net/embed/iframe/vth8yo4cnz"
allowtransparency="true" frameborder="0" scrolling="no"
class="wistia_embed" name="wistia_embed" allowfullscreen
mozallowfullscreen webkitallowfullscreen oallowfullscreen
msallowfullscreen width="770" height="433"></iframe>


<br/>


<p>Static content has been making a comeback lately, and justifiably so. The truth is that most of the content we interact with on the web won't change over time and complex content management systems (CMS) that dynamically generate HTML and such from databases on every call are really overkill. Sure, there are caching strategies and CDNs and such to hide some of the misery but you can't beat the speed, simplicity, and scalability of static content.</p>

<!--more-->


<p>The same can really be said of maps on the web. Most maps are published to convey some information that has been validated for the point in time in which it was published. Most of the organizations I've worked with, government and commercial, have a release process to vet the contents of a map before it is published. In effect, such organizations are making their map content static. The truth is that, like a CMS, a complex map server probably isn't necessary for most maps we interact with today on the web.</p>

<p>In fact, I can still clearly recall use cases from just a few years where such architectures were not only overkill but counterproductive. We typically distributed analysis results via web-based interactive maps. The results were typically valid for point in time during which an area of interest was studied. We ended up developing versioning schemes to preserve analysis results from being altered by the next bulk data set update. Another tack was to set up a separate map service pointed at a directory of shapefiles. All of this was to get around the basic fact that geospatial data at the time was not web-ready. GeoJSON helps solve that problem.</p>

<p>With modern client-side mapping libraries like <a href="http://leafletjs.com/">Leaflet</a> and <a href="http://www.openlayers.org/">OpenLayers</a>, and with content generation tools like TileMill, it has become increasingly easy to make beautiful, interactive web maps that require no specialized back-end server to deliver geospatial content. With WeoGeo's support, combined with the online editing capabilities of <a href="http://geojson.io/">geojson.io</a> from <a href="http://mapbox.com">MapBox</a>, the validation capability of <a href="http://geojsonlint.com/">GeoJSONLint</a> by <a href="http://twitter.com/JCSanford">Jason Sanford</a>, the <a href="https://help.github.com/articles/mapping-geojson-files-on-github">simple hosting capability of GitHub</a>, and the extended query API provided by <a href="http://gitspatial.com/">GitSpatial</a> (again by Jason Sanford), we are very close to having a complete GeoJSON-centric workflow.</p>

<p>Even as government data sites come back online, there are still good reasons to head over to WeoGeo and check out what they have. The customization capabilities alone (shown in the video above) make it very easy to get data for just your area of interest without having to download a lot of extra, unneeded data. The addition of GeoJSON support, in my opinion, shortens the workflow needed to get from data to information.</p>
]]></content>
  </entry>
  
</feed>
