<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: OpenLayers | geoMusings]]></title>
  <link href="http://blog.geomusings.com/blog/categories/openlayers/atom.xml" rel="self"/>
  <link href="http://blog.geomusings.com/"/>
  <updated>2013-06-19T06:48:18-04:00</updated>
  <id>http://blog.geomusings.com/</id>
  <author>
    <name><![CDATA[Bill Dollins]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Check Out the NREL Renewable Energy Applications]]></title>
    <link href="http://blog.geomusings.com/2012/01/16/check-out-the-nrel-renewable-energy-applications/"/>
    <updated>2012-01-16T00:00:00-05:00</updated>
    <id>http://blog.geomusings.com/2012/01/16/check-out-the-nrel-renewable-energy-applications</id>
    <content type="html"><![CDATA[<p>Among the items in the category of "<a href="http://blog.geomusings.com/2012/01/03/sharpening-the-saw/" target="_blank">what I care about</a>" are renewable energy and open-source geospatial tools. So I was happy to rediscover the <a href="http://maps.nrel.gov/" target="_blank">various online tools</a> by the <a href="http://www.nrel.gov/" target="_blank">National Renewable Energy Laboratory</a> in Golden, Colorado. Many of the tools have been available for some time but the <a href="http://www.nrel.gov/news/press/2012/1681.html">recent announcement</a> of the <a href="http://maps.nrel.gov/re_atlas" target="_blank">RE Atlas</a> application brought me back to them. <!--more--></p>

<p>RE Atlas is described as:</p>

<blockquote>The Renewable Energy Atlas is an interactive mapping tool to allow users to explore base level renewable energy resource datasets. The intention is to provide a broad overview of available data and provide appropriate links to allow users to explore the data in greater detail.</blockquote>


<p>I have also been browsing around the <a href="http://maps.nrel.gov/prospector">Solar Energy Prospector</a>, described as:</p>

<blockquote>The Prospector is a mapping tool developed for the Solar Power industry. This tool is designed to help developers site large-scale solar plants by providing easy access to solar resource datasets and other data relevant to utility-scale solar power projects.</blockquote>


<p>The front ends of these tools are built using open-source tools (<a href="http://openlayers.org/">OpenLayers</a>, <a href="http://drupal.org/">Drupal</a>, others). The interfaces provide a lot of capability, including query and download of underlying data. I like that the tools focus on making renewable energy data available to industry and private citizens for decision-making since uptake and investment by the private sector will be needed for renewable energy to gain lasting traction. These tools provide a good example of the potential for collaboration between government and industry to tackle challenging problems.</p>

<p>So, if you're looking for data related to renewable energy, these tools might be a good place to start.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Crazy Times - Coming Up For Air]]></title>
    <link href="http://blog.geomusings.com/2009/06/26/crazy-times-coming-up-for-air/"/>
    <updated>2009-06-26T00:00:00-04:00</updated>
    <id>http://blog.geomusings.com/2009/06/26/crazy-times-coming-up-for-air</id>
    <content type="html"><![CDATA[<p>It's been an extremely busy few months, as evidenced by the pace (or lack thereof) of blogging. I have been hopping between customer sites, mainly helping with ArcGIS Server implementations. We're also re-hosting an ArcIMS site for someone. I expect that to eventually transition as well but we have to get it moved first. I'm also working a pro-bono implementation of PostGIS/GeoServer/OpenLayers for the town of Green Mountain Falls, Colorado. That's been fun. It's great to see how a small town can marshall it resources (Boys Scouts with GPS collected trails as an Eagle Scout project) to get things done. The initial implementation will be simple as they are more interested in getting their data out there but then we'll circle back around to address public-service-type applications after that.</p>

<p>Significant changes are coming for <a href="http://pub.obtusesoft.com">zigGIS</a>. Abe, Paolo and I have been laying out a roadmap for its way ahead. Look for an announcement soon via <a href="http://twitter.com/zigGIS">zigGIS on Twitter</a>.</p>

<p>I have been having a lot of fun with the REST-based APIs from ESRI (Javascript, Flex, Silverlight/WPF). In particular, I've been happy with how extensible they are in terms of being able to support new data sources.
<a href="http://openlayers.org/pipermail/users/2009-June/012414.html">OpenLayers 2.8</a> and <a href="http://blog.opengeo.org/2009/06/17/geoexplorer-preview/">GeoExplorer</a> are also on my radar but that radar screen is getting pretty crowded.</p>

<p>All of this with less than a week to go before vacation. Whew!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[OpenGeo Suite - A Milestone]]></title>
    <link href="http://blog.geomusings.com/2009/06/01/opengeo-suite-a-milestone/"/>
    <updated>2009-06-01T00:00:00-04:00</updated>
    <id>http://blog.geomusings.com/2009/06/01/opengeo-suite-a-milestone</id>
    <content type="html"><![CDATA[<p>On May 28th OpenGeo <a href="http://blog.opengeo.org/2009/05/28/opengeo-suite-released/">announced the release of the OpenGeo Suite</a>. They also describe their open pricing structure for support of the suite.</p>

<p>This announcement represents a milestone for open-source geospatial software. If you are of a technical nature and are expecting a detailed discussion of the technical advantages of the OpenGeo Suite, you should probably stop reading now. The OpenGeo Suite is a milestone because it establishes a fair pricing model that addresses what, in my opinion, has been the primary barrier to the adoption of open-source GIS in many enterprises: risk.<!--more--></p>

<p>Am I saying open-source GIS is risky? No. The products included in the suite have gelled into a commonly used core of tools implemented in many places. In fact, some of those products (PostGIS, GeoServer, OpenLayers) are part of a pro bono project I am working for a small town. They are stable, robust, proven and highly capable. So why do I state risk as a barrier to adoption?</p>

<p>Many very capable technical people recognize the quality of the tools included in the OpenGeo Suite. However, the adoption of any technology platform in a well-run enterprise must usually pass muster with senior management who have the responsibility for allocating and managing resources. Many times, this would be CIO and/or the CFO. For these people, a strong business case must be made to justify platform adoption/switch. In this situation, the vendor model is attractive because vendors usually come prepared with pricing that shows what products will be received and what level of support for those products can be expected. As we all know, your actual mileage may vary here but these arrangements generally represent a contract that is binding to a certain extent and can help mitigate risks associated with the implementation and integration of a software platform.</p>

<p>For example, ESRI has been very successful in addressing these concerns with the implementation of ELAs in many large organizations in both government and the private sector. These agreements make technology available to the users that need them while simultaneously helping to better fix the cost of implementing the ArcGIS platform in an organization.</p>

<p>The funny thing about risk is that, for all the tools and techniques out there for quantifying it, a large portion of it is still based on perception. In general, the perception of risk equals the presence of risk.</p>

<p>I have seen this dynamic at work first hand with regard to open-source software (both geospatial and otherwise) in a few instances. The common themes I have observed (and tried to overcome) are:</p>

<ol>
<li><p>Lack of reliable support ? For most organizations, information technology is a tool that they use to do something else. They are generally uninterested in delving heavily into software development themselves and fear that committing to open-source may cause them to need to bring in additional developers should changes or updates be needed. This business stance is perfectly legitimate and is one that must be recognized and accepted by the open-source community. To simply say ?You have the code. Make the change and contrib back.? puts many organizations <em>into a situation they don?t want to get into in the first place</em>. So there are a lot of organizations that are looking for someone to call when something doesn?t work correctly.</p></li>
<li><p>Lack of integration between projects ? There can be some legitimacy to this. Many open-source projects are indeed independent entities. Many are also coupled together (such as GeoServer and GeoWebCache) but integration of products, if needed, may very well fall to the user if there is no prior association between the projects. Obviously, you can make the changes you need and contribute them back to the projects but see item number one for how many organizations view that whole process. You can also bring in a consultant to do the integration but the long-term O&amp;M of that becomes a concern.</p></li>
<li><p>Security ? There is a concern that, due to the crowd-sourced nature of open-source software, that malicious code could be inserted and that the implementing organization would need to scrub the code to ensure against this, leading to the need to have in-house experts that can understand the code. This stance speaks more to the mentality of the person who thinks this way than it does to any real problem with open-source. I can?t begin to explain the psychology but, having worked against it, I can say that people who think this way are <em>very</em> hard to dissuade. They feel that buying pre-compiled, closed-source, proprietary software is safer because the purchase transaction at least gives them some recourse in the event that something malicious happens. I suspect these people have never actually read a EULA.</p></li>
<li><p>Cost ? I saved the biggest for last. Nobody with funding authority in any enterprise believes in a free lunch (or free beer) and with good reason: it doesn?t exist. Everything costs something. I have seen many a technical staff get shot down on proposing open-source solutions because they lead off with ?it?s free!? All that says to senior management is that you haven?t done your homework and they stop listening at that point. They know that the piper gets paid somewhere and they need to know how much and what they get in return for it. In many cases, open-source looks nebulous from an ROI standpoint and that rolls back to the first three issues. In solving them, who is going to do it and how much will it cost and what capability do I get in return?</p></li>
</ol>


<p>There are other topics that have come up with regard to implementing open-source GIS that I have observed, but these four themes tend to always recur in some form or another.</p>

<p>This leads me back to the OpenGeo pricing model. It systematically addresses all of these concerns for a price that is straightforward. Those who have worked with open-source for a while know that the openness extends to being able to choose how to get the support you need. Paul Ramsey addressed this topic <a href="http://s3.cleverelephant.ca/geoconnexion-ramsey-2009-01.pdf">here</a> so it?s always been there for those willing to their homework. I find the OpenGeo model preferable because it provides peace of mind with regard to the integration and testing of the suite as a whole. Numerous installations have demonstrated that the tools included in the suite work well together but that?s not the same thing as saying that you have specifically tested them and verified their integration and can support the implementation of the suite.</p>

<p>Additionally, <a href="http://www.spatiallyadjusted.com/2009/05/28/opengeo-releases-opengeo-suite-puts-price-on-open-source-gis/">and James alludes to this</a>, the support draws from developers and contributors to the projects themselves. In most vendor technical support models, you are not getting access to the actual development teams. It is also important to note that OpenGeo supports integration with some proprietary tools and, at the enterprise level, for clustering and security. It also includes broad service-level definitions and discounted services rates (20% - 40% depending upon edition).</p>

<p>For many organizations, the question of adopting open-source GIS has been less about quantifying return on investment than it has been about quantifying the investment in the first place. The technical advantages of the tools in the OpenGeo Suite are readily apparent for many. I have spoken to a few people in the past who have found the features in PostGIS, GeoServer and OpenLayers in particular compelling but have shied away from adoption because of questions about total cost, including support and lifetime O&amp;M.</p>

<p>In my opinion, the OpenGeo pricing model represents a milestone because it finally marries the compelling technical capabilities of the tools in the suite with a clear, straightforward, and fair pricing/support model that quantifies costs of adoption/maintenance (if you use OpenGeo) and compares to proprietary vendor ELAs in an apples-to-apples fashion. This now gives an enterprise the tools it needs to do a true side-by-side cost/benefit analysis between open-source and proprietary geospatial tools and should begin to dispel misconceptions about the readiness of open-source geospatial tools for enterprise applications.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Writing GeoJSON from SharpMap, Part 1]]></title>
    <link href="http://blog.geomusings.com/2008/09/25/writing-geojson-from-sharpmap-part-1/"/>
    <updated>2008-09-25T00:00:00-04:00</updated>
    <id>http://blog.geomusings.com/2008/09/25/writing-geojson-from-sharpmap-part-1</id>
    <content type="html"><![CDATA[<p>In between proposals, white papers and the like, I?ve been able to do a little coding to keep myself sane. Recently, I have been playing with <a href="http://www.codeplex.com/sharpmap">SharpMap</a>, <a href="http://wiki.geojson.org/Main_Page">GeoJSON</a> and <a href="http://openlayers.org">OpenLayers</a>. But not necessarily in that order. Originally, I was looking over the GeoJSON spec to get more of a feel for it and decided that it would be fun (I know) to write an exporter for SharpMap. There is already a converter to write SharpMap geometries as WKT so I went ahead and built another one to convert to GeoJSON. In order to test it, I decided to use OpenLayers.<!--more--></p>

<p>Developing the exporter was pretty straightforward. I used the SharpMap.Converters.WellKnownText.GeometryToWKT class as a template. I created a GeoJson namespace and put a GeometryToGeoJson class in it. I then set about replacing the logic in the WKT with logic that generates GeoJSON. This should result in a class that behaves in the same way as its WKT counterpart but emits GeoJSON instead.</p>

<p>At this point, I am only dealing with geometry and geometry collections. I plan to move on to exporting feature collections in the near future. Also, I still need to persist the CRS information into the GeoJSON output.</p>

<p><strong>Step 1: Building the GeoJSON Writer</strong></p>

<p>As I mentioned, building the converter was pretty straightforward. I really just had to modify the logic of the existing WKT writer. I based the output on GeoJSON 1.0 RC1. The writer currently outputs points, linestrings, polygons, the various ?multi? flavors of those and geometry collections. As mentioned above, I haven?t gotten to features or CRS information yet.</p>

<p><strong>Step 2: Testing the Output</strong></p>

<p>I used the <a href="http://openlayers.org/dev/examples/vector-formats.html">OpenLayers ?Vector Formats? example</a> as a testbed. I built a simple WinForms GUI in which I could paste a WKT string, convert that to a SharpMap geometry and then write out GeoJSON from that. I then pasted the output into the OpenLayers demo and tried to render it. That process validated the outputs for each of the geometry types pretty quickly.</p>

<div style="text-align: center;"><a href="http://geobabble.files.wordpress.com/2008/09/sharpmap_geojson_bootstarp.png"><img alt="A lovely test GUI..." class="size-medium wp-image-324" height="144" src="http://geobabble.files.wordpress.com/2008/09/sharpmap_geojson_bootstarp.png" title="sharpmap_geojson_bootstarp" width="230" /></a><div style="text-align: center;font-size: 14px;">A lovely test GUI...</div></div>


<p><strong>Step 3: Generate Output From a Data Set</strong></p>

<p>Next, I modified the <a href="http://openlayers.org/dev/examples/geojson.html">existing OpenLayers GeoJSON demo </a> to make a call back to a server to retrieve GeoJSON from a SharpMap application. The existing demo has a GeoJSON string hard-coded into the JavaScript. I merely replaced this with an AJAX call that retrieves it from the server.</p>

<p>Next, I built an ASP.NET handler (thanks <a href="http://twitter.com/TheSteve0">@TheSteve0</a>) to receive the call from the client, access the data (PostGIS in this case, served from that data I?ve been using for my ArcSDE work), write the geometries into a GeoJSON geometry collection and return it back to the client. Currently, the client passes a query string to tell the server what data is being requested. I plan to implement that in a RESTful manner in a future iteration but this works for now.</p>

<p><strong>Step 4: Running the Code and Displaying the Data</strong></p>

<p>I changed the OpenLayers demo page only minimally to make a call to retrieve the GeoJSON. I implemented an asynchronous call so the basemap would display without waiting for the GeoJSON data to come back. The data set I used contained 408 military installation polygons stored in PostGIS. SharpMap seems to persist the data fairly quickly but it bogged down on the client side on my first run. In both IE and FireFox, the browser would hang and eventually display a message that a script was causing the browser to run slowly. In each case, I had to terminate the script.</p>

<div style="text-align: center;"><a href="http://geobabble.files.wordpress.com/2008/09/sharpmap_geojson_output.png"><img alt="The orange blobs with the outlines are mine." class="size-medium wp-image-324" height="255" src="http://geobabble.files.wordpress.com/2008/09/sharpmap_geojson_output.png?w=300" title="sharpmap_geojson_output" width="300" /></a><div style="text-align: center;font-size: 14px;">The orange blobs with the outlines are mine.</div></div>


<p>On my second pass, I throttled the server-side code back to return only the first ten records. In this case, it returned and displayed almost instantaneously. There were my installation polygons!</p>

<p>On each successive pass, I increased the number of polygons and the client side slowed down down accordingly. Somewhere around 300 polygons, it ground to a halt. I put an alert box in before this call in the client-side javascript:</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='js'><span class='line'><span class="nx">vector_layer</span><span class="p">.</span><span class="nx">addFeatures</span><span class="p">(</span><span class="nx">geojson_format</span><span class="p">.</span><span class="nx">read</span><span class="p">(</span><span class="nx">gj</span><span class="p">));</span>
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>That alert always displays very quickly so there seems to be something inefficient about the geojson_format.read call. <del datetime="00">I?d dig into that more but I upgraded to FireFox 3, which has my FireBug broken (grrrrr).</del> I?ll look into that more later (I have the additional problem of being javascript-challenged). Anyway, OpenLayers was more of a visualization tool for the SharpMap effort so I?m less concerned with that issue at the moment.</p>

<p>As the title of the post implies, I?ll circle back around and update things as I progress. I need to clean up the code for the writer (all of the comments are still the ones from the WKT writer). Additionally, I need to now look at extending to write features, not just geometry. I also want to make the server-side app RESTful. Eventually, I?ll also deploy the app to a demo location where anyone can hit it. As you can see, I have my work cut out for me.</p>

<p>BTW, here are the versions involved on this pass:
OpenLayers: 2.6
SharpMap: 0.9 build 34320
Visual Studio: 2008
PostGIS: 1.3.3</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[FedUC Plenary - 47.53]]></title>
    <link href="http://blog.geomusings.com/2008/03/25/feduc-plenary-4753/"/>
    <updated>2008-03-25T00:00:00-04:00</updated>
    <id>http://blog.geomusings.com/2008/03/25/feduc-plenary-4753</id>
    <content type="html"><![CDATA[<p>For those of you keeping track at home, the reference to <a href="http://www.openlayers.org/">OpenLayers</a> in <a href="http://www.esri.com/news/podcasts/audio/speaker/feduc08_dangermond.mp3">Jack Dangermond's FedUC plenary talk</a> comes at approximately 47:53.</p>
]]></content>
  </entry>
  
</feed>
