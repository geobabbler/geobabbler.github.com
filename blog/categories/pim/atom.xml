<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: PIM | geoMusings]]></title>
  <link href="http://blog.geomusings.com/blog/categories/pim/atom.xml" rel="self"/>
  <link href="http://blog.geomusings.com/"/>
  <updated>2013-03-27T14:00:10-04:00</updated>
  <id>http://blog.geomusings.com/</id>
  <author>
    <name><![CDATA[Bill Dollins]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[ToGeoJson and ToWKT for the Esri FGDB API]]></title>
    <link href="http://blog.geomusings.com/2012/08/24/togeojson-and-towkt-for-the-esri-fgdb-api/"/>
    <updated>2012-08-24T00:00:00-04:00</updated>
    <id>http://blog.geomusings.com/2012/08/24/togeojson-and-towkt-for-the-esri-fgdb-api</id>
    <content type="html"><![CDATA[<p>In support of some of our ongoing <a href="http://www.zekiah.com/index.php?q=blog/topics/pim" target="_blank">PIM</a> work, we've been integrating the <a href="http://www.esri.com" target="_blank">Esri</a> <a href="http://resources.arcgis.com/content/geodatabases/10.0/file-gdb-api" target="_blank">File Geodatabase (FGDB) API</a> into some tools. Without going into a level of detail that would hijack this post, one of the many functions performed by some of the tools is to validate physical spatial databases against established data models to analyze compliance and identify differences. These databases may be in Esri or non-Esri formats and we have traditionally handled Esri geodatabases through ArcObjects since it provides a relatively uniform interface across the various flavors of geodatabase.</p>

<p><img alt="" style="text-align: center;" height="300" src="http://geobabble.files.wordpress.com/2012/08/fileapi2.png" title="FGDB API" width="287" /></p>

<p>Of course, ArcObjects requires an ArcGIS license of some sort and we are finding out that this is not always available to users in the field under many situations so the FGDB API gets past that for file geodatabases, at least. <!--more--></p>

<p>Since the PIM is really a configuration management system for spatial data models, the tools need to support a wide variety of scenarios, including data migration between platforms, versions, approved user-defined implementations, etc. in a manner that's compliant with the data model being managed. As a result, some ETL-like tools are built into the workflows, although ETL is not a primary focus of the PIM.</p>

<p>Since the PIM tools are written in .NET, I built a couple of extension methods to assist with some of the workflows in the existing tools. They enable outbound support for GeoJSON and WKT. The GeoJSON methods work on RowCollection, Row, and ShapeBuffer objects to create FeatureCollection, Feature, and Geometry types respectively. In practice, they'd be used something like this example from a very simple ASP.NET MVC sample application:</p>

<p>{% codeblock lang:csharp %}
var path = Server.MapPath("/App_Data/mvc_samples.gdb");
Geodatabase gdb = Geodatabase.Open(path);
Table statesTable = gdb.OpenTable("\us_states");
RowCollection rows = statesTable.Search("*", "STATE_NAME LIKE 'M%'", RowInstance.Recycle);
var rval = rows.ToGeoJson();
gdb.Close();
Response.ContentType = "application/json";
object result = this.Content(rval);
return result as ActionResult;
{% endcodeblock %}</p>

<p>The WKT method only works on ShapeBuffer objects to export geometries. The code for the extension methods themselves can be found on <a href="https://github.com/geobabbler/FgdbExtensions" target="_blank">GitHub here</a>. It includes a five-minutes-or-less MVC sample from which the above code was lifted. I know I'll be doing some cleanup on the GeoJSON in the near future and I'll probably add support for EWKT to smooth our interactions with <a href="http://postgis.refractions.net/" target="_blank">PostGIS</a> and <a href="http://www.gaia-gis.it/gaia-sins/" target="_blank">SpatiaLite</a> and may also add support for WKB.</p>

<p>As I said, I developed these to support workflows in existing applications. If you're looking to just perform data conversion or ETL, you should just use <a href="http://www.gdal.org/ogr/" target="_blank">OGR</a> or <a href="http://www.safe.com/" target="_blank">FME</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Breaking Radio Silence]]></title>
    <link href="http://blog.geomusings.com/2012/06/07/breaking-radio-silence/"/>
    <updated>2012-06-07T00:00:00-04:00</updated>
    <id>http://blog.geomusings.com/2012/06/07/breaking-radio-silence</id>
    <content type="html"><![CDATA[<p>Things have been kind of quiet on the blog lately due to things being busy at work. I call that a good problem to have. Since the beginning of the year, I've written a a lot of proposals for a mixture of potential customers. Interestingly, I'm seeing a lot more call for "GIS Analyst" work. One trend I've noticed, at least in the Federal sector, is that the time between proposal due dates and award announcements seems to be lengthening. That may be an indication of the ongoing flux in funding and organizations try to figure out how to fund their requirements. It will be interesting to see how it shakes out. Of course, it's good that the opportunities are there in the first place.</p>

<p><a href="http://geobabble.files.wordpress.com/2012/06/microphone.jpg"><img alt="" class="aligncenter size-full wp-image-2664" height="413" src="http://geobabble.files.wordpress.com/2012/06/microphone.jpg" title="microphone" width="413" /></a></p>

<p>One the technical side of things, I've been involved in a smattering of things that's made it hard to roll up one good post. I'm pretty heavily involved in the PIM efforts that my colleague, Barry Schimpf, <a href="http://www.zekiah.com/index.php?q=blog/topics/pim" target="_blank">has been blogging about</a> over on the <a href="http://www.zekiah.com" target="_blank">Zekiah</a> blog. <!--more--> Historically, the PIM data structures have been housed in Microsoft SQL Server, but we've been working on porting it to other platforms to provide options to end users. We've done an initial port to <a href="http://www.postgresql.org/" target="_blank">PostgreSQL</a> but we've been spending most of our time on a <a href="http://www.sqlite.org/" target="_blank">SQLite</a>/<a href="http://www.gaia-gis.it/gaia-sins/" target="_blank">SpatiaLite</a> version. This has taken two forms. First is the port of the PIM structure itself to SQLite to make it easier to provide some of the PIM services such as profiling, version-to-version migrations, dataset generation, and validation in remote, field-based settings. Second is the generation/validation of physical implementations in SpatiaLite. This is being done for a customer who is expecting to do field data collection using SpatiaLite and these services will be helpful in enhancing data quality at the point of collection. Additionally, the SpatiaLite aspect of this work has had me living within <a href="http://qgis.org/" target="_blank">QGIS</a> lately.</p>

<p>Another thing I've been experimenting with is the use of <a href="http://nodejs.org/" target="_blank">Node.js</a> for real-time data processing. Our long-standing work in the situational awareness realm has had us working with real-time data feeds for a long time. I'm interested in the possibility of using Node to tackle some of the feed collection tasks. I've used an event-driven approach for such tasks in the past so that aspect of Node is quite familiar to me but the use of Javascript, its ease of deployment and potential scalability are intriguing to me. I'm coming late to the party with Node, primarily due to my rustiness with Javascript, but I'm liking what I'm seeing so far.</p>

<p>Beyond those major things, I've had the opportunity to start working with <a href="http://postgis.org/" target="_blank">PostGIS</a> 2.0 and play more with <a href="http://leaflet.cloudmade.com/" target="_blank">Leaflet</a> and <a href="http://mapbox.com/" target="_blank">MapBox</a>. On the development side of things, these efforts have had be jumping back and forth a lot between C#, Javascript and a little bit of Python, as well as between Windows and Linux, depending on the task.</p>

<p>You'll notice that I didn't mention any <a href="http://www.esri.com" target="_blank">Esri</a> tools. That's primarily because recent demand from my customers has led me to a different tool set. I expect that to level out somewhat in the near future since many of the outstanding proposals I mentioned have a strong Esri flavor. As always, having a broad toolbox can be an asset in consulting. I'll be skipping San Diego again this year. I'm finding that Esri's Federal Conference in DC is of such increasing quality each year that it fulfills my needs for Esri-related information. That's really okay with me because I'd rather spend as much of the summer with my family as possible. So it's not so much a down-vote of Esri as my taking advantage of options that fit into my life better.</p>

<p>I hope to be able blog in more detail about some of these efforts as I get farther along with them. Times like this make it exciting to work in the geospatial field. There's a lot of churn in the market right now with regard to tools and technologies. I'm not sure I can perceive any meaningful gap between the capabilities of open-source and proprietary geospatial tools anymore. As a result, there are a lot of options to choose from for building robust systems and applications. It looks to be a fun summer.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Configuration Management for Geospatial Data Models]]></title>
    <link href="http://blog.geomusings.com/2012/03/27/configuration-management-for-geospatial-data-models/"/>
    <updated>2012-03-27T00:00:00-04:00</updated>
    <id>http://blog.geomusings.com/2012/03/27/configuration-management-for-geospatial-data-models</id>
    <content type="html"><![CDATA[<p>I wanted to take a opportunity to do something I don't often do, and draw attention to a series of posts that's going on over on <a href="http://www.zekiah.com/index.php?q=blog">my company's blog</a>. About a year ago, my company, <a href="http://www.zekiah.com">Zekiah Technologies</a> joined forces with Upper 90 Systems. Upper 90 was probably best known for their work building tools that supported the Spatial Data Standard for Facilities, Infrastructure, and Environment (SDSFIE), which is a data model that is used by the US DOD to standardize the representation of GIS data for the purpose of performing facilities management on military installations.</p>

<p><a href="http://www.acq.osd.mil/ie/bei/disdi/factsheet_sdsfie.pdf" target="_blank">SDSFIE</a> (PDF) has existed for some time, with several versions of the standard being rolled out to its diverse user community. Through that process, we've learned a thing or two about configuration management of widely-implemented geospatial data models. This understanding has been turned into a series of tools designed to help with the issues surround lifecycle management of a data model (as opposed to physical databases themselves). <!--more--></p>

<p>The approach and tools are loosely referred to as the "platform-independent model", or PIM. We call it that because the model defines the rules that govern how to create and manage a geospatial database in compliance with a given data standard, but the model is not the database itself. As a result, we can support physical implementations on any number of platforms (Esri, PostGIS, Oracle Spatial, SpatiaLite, Bentley, Autodesk, etc.). The tools give users the ability to perform version management, schema generation, compliance checking, profiling, development of migration paths between versions and many other functions.</p>

<p>Barry Schimpf, the former president of Upper 90 Systems and now my colleague at Zekiah, has been working on a series of posts describing this approach and, eventually, the tools. Three posts have gone up with others on the way:</p>

<p><a href="http://www.zekiah.com/index.php?q=blog/2012/01/13/expanding-usefulness-geospatial-data-standards" target="_blank">Expanding Usefulness of Geospatial Data Standards</a>
<a href="http://www.zekiah.com/index.php?q=blog/2012/03/19/applying-flexible-yet-standard-geospatial-conventions" target="_blank">Applying Flexible, Yet Standard, Geospatial Conventions</a>
<a href="http://www.zekiah.com/index.php?q=blog/2012/03/24/understanding-geospatial-data-rules-platform-independent-model-pim" target="_blank">Understanding Geospatial Data Rules in the Platform Independent Model (PIM)</a></p>

<p>The approach Barry discusses has already been leveraged to support Federal data models beyond SDSFIE so we know it is transferable. We think it could have benefits for at the state, local, or regional levels as well. I encourage you to check out the posts and keep an eye out for more as they emerge.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Speaking of the 84%...]]></title>
    <link href="http://blog.geomusings.com/2012/02/08/speaking-of-the-84/"/>
    <updated>2012-02-08T00:00:00-05:00</updated>
    <id>http://blog.geomusings.com/2012/02/08/speaking-of-the-84</id>
    <content type="html"><![CDATA[<p>HT to <a href="http://sproke.blogspot.com/2012/02/game-changer-open-source-mapping-in.html">Sophia Parafina for the 84%</a>.</p>

<p><strong>UPDATE</strong>: The NSIS script at utility batch file discussed here is now on github at <a href="https://github.com/geobabbler/pgstandalone" target="_blank">https://github.com/geobabbler/pgstandalone</a>. I'll post a readme in the next day or so.</p>

<p>A few months ago, I asked the following question on Twitter and got this reply from Paul Ramsey:</p>

<p>{% tweet http://twitter.com/pwramsey/status/136565522836897796 %}</p>

<p>We are working with a Federal Government customer that had the interesting policy that users can install software as long as it makes no changes to the Windows registry. These users are currently running a mix of Windows 7 and XP. We are working with them to help manage one of their data models. In this case, it's more about performing configuration management on the model/standard itself rather than physical databases with real data in them. It's a topic we touched on over at the Zekiah blog <a href="http://www.zekiah.com/index.php?q=blog/2012/01/13/expanding-usefulness-geospatial-data-standards" target="_blank">here</a> and an approach we have used successfully for years to manage the <a href="http://www.sdsfie.org/" target="_blank">SDSFIE</a> data standard. <!--more--></p>

<p>So we've applied the technique to another data standard for another Federal organization. In this case, we need to distribute tools to help data modelers work with the platform-independent logical model (PIM) on their own desktops. Typically, this has been centrally managed and accessible via an implementation in SQL Server. (Don't get wrapped around the term "platform-independent." We use it in a different context within this work.) Since we have to distribute to desktops, and SQL Server makes a slew of registry entries, and <a href="http://www.postgresql.org" target="_blank">PostgreSQL</a> has no licensing issues, we decided to go the PostgreSQL route.</p>

<p>It turns out, this was pretty easy. After doing the work for our approach, I have subsequently found posts showing a similar approach (as always, it depends on the day and the search term), which was nice because they sort of validated what I had already done.</p>

<p>Paul was on the right track with using the Windows binaries from the PostgreSQL site. Natively, PostgreSQL doesn't need any registry entries, which makes sense given that it also runs on Linux and Unix. Registry entries are typically introduced by the one-click installers that do helpful things like setting PostgreSQL up as a service and a few other things that require registry entries on Windows. These are very useful things that I avail myself of when I use PostgreSQL on Windows. In this particular use case, those features were not helpful.</p>

<p>One thing that you'll notice when you use the one-click installer is that you'll end up with a batch file called "pg_env.bat" in the install folder for your version. It looks something like this:</p>

<p>{% codeblock lang:powershell %}
@ECHO OFF
REM The script sets environment variables helpful for PostgreSQL</p>

<p>@SET PATH="C:\Program Files (x86)\PostgreSQL\8.4\bin";%PATH%
@SET PGDATA=C:\Program Files (x86)\PostgreSQL\8.4\data
@SET PGDATABASE=postgres
@SET PGUSER=postgres
@SET PGPORT=5432
@SET PGLOCALEDIR=C:\Program Files (x86)\PostgreSQL\8.4\share\locale
{% endcodeblock %}</p>

<p>As you can see, I'm working with version 8.4 of PostgreSQL. That version is what has been blessed but I am also rolling up an implementation of this approach for 9.1 as we expect to get that approval soon.</p>

<p>With this batch file and the unzipped binaries, we have everything we need to run PostgreSQL without running an installer that makes registry entries. Now all we need to do is tell each user to unzip the binaries, edit the batch file to point to the correct paths, open a command window and run the batch file...</p>

<p>...Clearly, there was a little more work to do to make this operate smoothly.</p>

<p>First, we wanted <a href="http://www.postgis.org/" target="_blank">PostGIS</a> in our build. As I mentioned before, the PIM represents a logical model that doesn't store actual data, but we wanted it to know about PostGIS data types. Additionally, we wanted to distribute the PIM with PostgreSQL. In this case, we did a little bit of prep work using a standard install of PostgreSQL to add PostGIS (and its template database) and build/populate our PIM database.</p>

<p>Once we had this done, we moved the data directory over to our "unzipped" instance of PostgreSQL. We tested by running our batch file from the command prompt and starting PosgreSQL the same way. In our case, we changed the listening port to 54325. We then attempted to connect via pgAdmin3 and had success:</p>

<div style="text-align: center;"><img alt="" class="size-full wp-image-2471" height="274" src="http://geobabble.files.wordpress.com/2012/02/pgpost1.png" title="pgpost1" width="235" /><div style="text-align: center; font-size: 14px">Connection successful!<br /></div></div>


<p>This is all well and good, but probably still a bit much to ask a user to do. So we built an installer. In this case, we used the <a href="http://nsis.sourceforge.net/Main_Page" target="_blank">Nullsoft Scriptable Install System</a> (NSIS) to build our own installer and ensure that no registry entries were made. So once we had our instance/data prepped the way we wanted it, we zipped it all back up for inclusion in the installer. The NSIS script for the installer is at the end of this post.</p>

<p>For the installer to work, we also made use of the <a href="http://nsis.sourceforge.net/ZipDLL_plug-in">ZipDLL plug-in</a> for NSIS. The installer essentially prompts the user to specify the install location then unzips the PostgreSQL binaries/data, builds the driver batch file and places shortcuts on the user's desktop. It's really that simple. We have a utility (also a batch file) that builds the driver batch file as the installer runs. When it's done, the installer cleans up the zip file and the utility. The resulting driver batch file looks like this (where the user specified "C:\Program Files (x86)\PGStandalone11" as the install location):</p>

<p>{% codeblock lang:powershell %}
REM This file was automatically generated
REM This script sets environment variables helpful for PostgreSQL
@SET PATH="C:\Program Files (x86)\PGStandalone11\bin";%PATH%
@SET PGDATA=C:\Program Files (x86)\PGStandalone11\data
@SET PGDATABASE=postgres
@SET PGUSER=postgres
@SET PGPORT=54325
@SET PGLOCALEDIR=C:\Program Files (x86)\PGStandalone11\share\locale
CALL "C:\Program Files (x86)\PGStandalone11\bin\postgres.exe"
{% endcodeblock %}</p>

<p>We also drop two shortcuts on the desktop:</p>

<p><img alt="" class="aligncenter size-full wp-image-2475" height="161" src="http://geobabble.files.wordpress.com/2012/02/pgpost2.png" title="pgpost2" width="316" /></p>

<p>The shortcut labeled "Start PostGIS PIM" executes the batch file above. The shortcut labeled "Manage PostGIS PIM" starts pgAdmin3. I am currently trying to get pgAdmin3 to read the connection information from its settings.ini file instead of looking to the registry. If the user adds the connection on their own, it will write information to the HKCU hive of the registry. This may end up being acceptable but I probably still won't let it go until I solve this problem.</p>

<p>Once we get this completely finalized, I'll make the script and the utilities available. Another reason that I love PostgreSQL is that things like this seem to end up being easier than you would think. That's a sign of a well-built piece of software, in my opinion.</p>

<p>And here's the installer's NSIS script:</p>

<p>{% codeblock lang:text %}
!define CO_DIR "Zekiah Technologies"
!define NAME "Standalone PostgreSQL/PostGIS Install for Windows"
!define SHORTNAME "PGStandalone"
!define UNINSTALLER "uninstall.exe"</p>

<p>OutFile "setup_${SHORTNAME}.exe"
Name "${NAME}"
Caption "${NAME} Setup"
InstallDir "$PROGRAMFILES\${SHORTNAME}"
CompletedText "Success."
XPStyle "On"
InstallColors /windows</p>

<p>Page directory
Page instfiles
ShowInstDetails show</p>

<p>Section "Install"</p>

<pre><code>SetOutPath $INSTDIR

; Create uninstaller first, so user can clean up if we barf.
WriteUninstaller "$INSTDIR\${UNINSTALLER}" ;this actually does nothing right now

; Extract all the files.
DetailPrint "Extracting files..."
File pg.zip
ZipDLL::extractall "$INSTDIR\pg.zip" "$INSTDIR"

;Write batch file using INSTDIR to set correct paths
Call WriteBatchFile
DetailPrint "OK: Batch file written"

Call OutputToTemp
GetFullPathName /short $0 $INSTDIR
Delete "$INSTDIR\pg.zip"

; Add start menu shortcuts.
DetailPrint "Adding shortcuts..."
SetShellVarContext all
CreateDirectory "$SMPROGRAMS\${NAME}"
SetOutPath "$SMPROGRAMS\${NAME}"
CreateShortCut "Uninstall.lnk" "$INSTDIR\${UNINSTALLER}"
CreateShortCut "$DESKTOP\Start PostGIS PIM.lnk" "$INSTDIR\pg_standalone.bat" ""
CreateShortCut "$DESKTOP\Manage PostGIS PIM.lnk" "$INSTDIR\bin\pgAdmin3.exe" ""

; Success.
DetailPrint "All Done!"
</code></pre>

<p>SectionEnd</p>

<p>Function OutputToTemp</p>

<pre><code>ExpandEnvStrings $5 "%TEMP%"
SetOutPath $5
</code></pre>

<p>FunctionEnd</p>

<p>Function un.OutputToTemp</p>

<pre><code>ExpandEnvStrings $5 "%TEMP%"
SetOutPath $5
</code></pre>

<p>FunctionEnd</p>

<p>Function WriteBatchFile</p>

<pre><code>; execute utility to create batch file to execute PostgreSQL

Call OutputToTemp
File "utils\make_pg_env.bat"
ExecWait '"$5\make_pg_env.bat" "$INSTDIR"'
</code></pre>

<p>FunctionEnd</p>

<p>UninstPage uninstConfirm
UninstPage instfiles
ShowUninstDetails hide</p>

<p>Section "Uninstall"</p>

<pre><code>; Remove all start menu shortcuts.
DetailPrint "Removing shortcuts..."
SetShellVarContext all
Delete "$SMPROGRAMS\${NAME}\*"
RmDir "$SMPROGRAMS\${NAME}"

DetailPrint "Removing files..."

Delete "$INSTDIR\${UNINSTALLER}"
RmDir "$INSTDIR"
</code></pre>

<p>SectionEnd
{% endcodeblock %}</p>
]]></content>
  </entry>
  
</feed>
