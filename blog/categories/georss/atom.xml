<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: georss | geoMusings]]></title>
  <link href="http://blog.geomusings.com/blog/categories/georss/atom.xml" rel="self"/>
  <link href="http://blog.geomusings.com/"/>
  <updated>2013-10-17T12:01:28-04:00</updated>
  <id>http://blog.geomusings.com/</id>
  <author>
    <name><![CDATA[Bill Dollins]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Using Dynamic Non-Spatial Data In GeoCommons]]></title>
    <link href="http://blog.geomusings.com/2011/09/07/using-dynamic-non-spatial-data-in-geocommons/"/>
    <updated>2011-09-07T00:00:00-04:00</updated>
    <id>http://blog.geomusings.com/2011/09/07/using-dynamic-non-spatial-data-in-geocommons</id>
    <content type="html"><![CDATA[<p>In <a href="http://blog.geomusings.com/2011/08/30/prying-data-open/">my previous post</a>, I described how I used a Python script to scrape power outage information from a local web site and convert it into an RSS feed. In this post, I'll show how I used GeoCommons to visualize the changing information over time.</p>

<p>The process starts by creating a data set in GeoCommmons based on a URL link to the feed created in the previous post. The general process for doing that can be found <a href="http://geocommons.com/help/User_Manual#Add-a-URL-Link-from-the-web">here</a> in the GeoCommons documentation.</p>

<!--more-->


<p>My feed is not a GeoRSS feed so it has no location data of its own for GeoCommons to work with. During the upload process, I reached this screen, which starts the process of helping to attach location to my data.</p>

<p><img alt="" class="aligncenter size-full wp-image-2037" height="388" src="http://geobabble.files.wordpress.com/2011/09/geocommons4.png" title="Geolocating data in GeoCommons" width="590" /></p>

<p>The feed summarizes power outage by ZIP code so I chose "Join with a boundary dataset" so that I could join it with ZIP code boundaries I had previously uploaded.</p>

<p>I selected the attribute in my feed (title) that was to be used to join with a corresponding attribute in the boundary data set (Zip) as shown below.</p>

<p><img alt="" class="aligncenter size-full wp-image-2038" height="345" src="http://geobabble.files.wordpress.com/2011/09/geocommons6.png" title="GeoCommons6" width="590" /></p>

<p>You'll notice that the success message indicates three features were matched. This is true for this version of the feed because ZIP codes with zero power outages are not reported. The join, however, updates itself as the feed updates so more or less polygons may appear in the current version, depending upon feed content.</p>

<p>After reviewing my data and providing some basic metadata, GeoCommons performed the join and my data set was ready to go.</p>

<p><img alt="" class="aligncenter size-full wp-image-2041" height="443" src="http://geobabble.files.wordpress.com/2011/09/geocommons9.png" title="Completed data set" width="554" /></p>

<p>In the image above, you'll notice a link labeled "fetch latest." That link, which is formatted as "http://geocommons.com/overlays/{overlayid}/fetch," can be used to manually get the latest version of the feed, which is stored by GeoCommons. Essentially, GeoCommons stores the state of each feature in the data set as the feed is fetched so you build a "version history" your data. As long as you have a date/time attribute, you can use GeoCommons to visualize the changes over time.</p>

<p>In addition to the Python code from previous post, I also used a variant on the script found at <a href="http://www.voidspace.org.uk/python/articles/authentication.shtml">http://www.voidspace.org.uk/python/articles/authentication.shtml</a>. The fetching capability requires authentication so I modified the script to call the "fetch" URL using my GeoCommons user name and password. The script may be overkill but work perfectly without any changes.</p>

<p>On the server, I wrote a four-line batch file to act as a driver for the whole process. This batch file is what is called by a scheduled task in Windows.</p>

<p>{% codeblock lang:powershell %}
del <em>.xml
del </em>.pickle
python SmecoFeedObj.py
python fetchlatest.py
{% endcodeblock %}</p>

<p>As you can see, the batch is very simple. It deletes the old files, scrapes the latest version and writes new files (SmecoFeedObj.py) and then updates the GeoCommons data set (fetchlatest.py).</p>

<p>The server is a Windows server so I set up a scheduled task (How to: <a href="http://support.microsoft.com/kb/308569">XP</a>, <a href="http://windows.microsoft.com/en-US/windows-vista/Schedule-a-task">Vista</a>, <a href="http://windows.microsoft.com/en-US/windows7/schedule-a-task">Windows 7</a>, <a href="http://technet.microsoft.com/en-us/library/cc738106(WS.10).aspx">Server 2003</a>, <a href="http://technet.microsoft.com/en-us/library/cc725745.aspx">Server 2008</a>). I set my task up to run once an hour so the latest data is scraped and pushed to GeoCommons hourly.</p>

<p>With the data set now created and being updated, it can be used to make maps in GeoCommons to visualize the changing data. I created two maps to demonstrate this. <a href="http://geocommons.com/maps/97820">The first</a>, using a filter, allows a user to filter the feed data to a time window of their choosing and map just the outage data for that time window.</p>

<p>The <a href="http://geocommons.com/maps/97820">second map</a>, shown below, uses GeoCommons animation capability to allow a user to "play through" the data based upon the publication date/time. A user can either drag the time slider manually or let it play automatically. They can also adjust the width of the slider to narrow/widen the time window. I've been told by GeoIQ that animation is under active improvement so I'm interested to see how it evolves. This was my first attempt at using it with my own data so I'm sure I'm not using it optimally. That said, I'm impressed with how easy it was to set up a time-based animation.</p>

<div style="text-align: center"><a href="http://geocommons.com/maps/97820"><img alt="" class="size-full wp-image-2043" height="278" src="http://geobabble.files.wordpress.com/2011/09/geocommons10.png" title="GeoCommons map animating power outage data" width="590" /></a><div style="text-align: center;font-size: 14px;">GeoCommons map animating power outage data<br/></div></div>


<p>All-in-all, it took me about 4 hours to go from data embedded in an HTML page to a working map animation. That really speaks to the power of the tools available today, from programming languages like Python and open standards like RSS to online tools like GeoCommons, as well as a host of others I didn't use for this work. It is becoming easier all the time to integrate and use spatial tools to exploit data from traditionally non-spatial sources and share the results widely. As traditional "GIS" fades into the background, the resulting fusion of more standard technologies is opening a wider world of possibilities.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Completing the Model]]></title>
    <link href="http://blog.geomusings.com/2010/10/27/completing-the-model/"/>
    <updated>2010-10-27T00:00:00-04:00</updated>
    <id>http://blog.geomusings.com/2010/10/27/completing-the-model</id>
    <content type="html"><![CDATA[<p>It has been a truism for some time that GIS enables us to build models of the Earth. Esri Press has even offered a book on geodatabase design called ?<a href="http://esripress.esri.com/display/index.cfm?fuseaction=display&amp;websiteID=27">Modeling Our World</a>? for a while. Traditionally, GIS has given us the ability to model the surface of the earth (in a broad sense), including our effect upon it. That can be extended to subsurface modeling and weather modeling and similar concepts but, in general, GIS has focused on the surface of the earth, plus or minus a few thousand meters or so. <!--more--></p>

<p>One important aspect of our world that has defied modeling with traditional GIS tools is us. While it?s true that we can use GIS to do demographic analysis that market analysis and the like, those applications have typically fallen into the sweet spot of traditional GIS in that they typically involve analyzing aggregations of data captured over a period of time. These applications, like most others that are well-handled by GIS, are slow-moving.</p>

<p><img alt="" height="308" src="http://bulgaria.usembassy.gov/uploads/sO/bX/sObXJ0cSW96V4g6DMGj4hA/earth.gif" title="Earth" width="303" /></p>

<p>All of these applications have a lot of value (or else most of us wouldn?t be doing our current jobs), but they present an incomplete picture. If we were to take the model of our world as represented by traditional GIS, turn it into reality and place that world in orbit; I suspect an alien visitor would come upon it and find a lifeless world with strong evidence that a people once lived there. GIS does a great job of showing the expansion of new subdivisions and their parcels, road networks, utility networks, the demographic makeup of their residents and the like. But, every day, each of those people leaves their homes and goes to countless locations throughout their day for brief time periods and myriad reasons. Such movements are fleeting and not well-handled by traditional GIS tools.</p>

<p>Over the last few years, the emergence of location-aware social media has given us a window into these fleeting aspects of human behavior. Tools such as <a href="http://foursquare.com">Foursquare</a>, <a href="http://twitter.com">Twitter </a>and <a href="http://facebook.com">Facebook</a>, combined with microformats such as <a href="http://www.georss.org/Main_Page">GeoRSS</a> and <a href="http://geojson.org/">GeoJSON</a> and wired into advanced smartphone platforms (and many other technologies) are building a ?story? that is profound. We can see who was doing what, where they did it and when. This clearly has some ?Big Brother? implications that we must consider. But, over time, it can provide a detailed picture of almost archaeological significance (imagine the value of the Twitter stream of one day in Republican Rome).</p>

<p>The exploitation of these information streams is still in its infancy. We?ll see a lot of micro-targeting of content such as advertising (cast a smaller net more precisely) and other such applications. Geo-fencing has also gotten a lot of press lately. That?s a concept that has been worked with great value over the years in the defense and security worlds, but may have found its ?killer app? with location-aware social media. Many other applications and tools are on the way; I?m sure, as more people turn their imagination to them.</p>

<p>So, while there?s been a lot of churn regarding the value of such streams (?Don?t clutter my Twitter timeline with your check-ins!?), they are here to stay. They help us complete the model by enabling us to model ourselves; the way we live, at the pace we live.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[GeoLocation API for Twitter Announced]]></title>
    <link href="http://blog.geomusings.com/2009/08/20/geolocation-api-for-twitter-announced/"/>
    <updated>2009-08-20T00:00:00-04:00</updated>
    <id>http://blog.geomusings.com/2009/08/20/geolocation-api-for-twitter-announced</id>
    <content type="html"><![CDATA[<p>Ryan Sarver <a href="http://blog.twitter.com/2009/08/location-location-location.html">announced today</a> the availability of a geolocation API for Twitter. It even supports GeoRSS and GeoJSON. This could be a potentially significant new step for Twitter. It looks like the API will be opened to <del datetime="2009-08-20T23:50:17+00:00">platform developers first</del> everyone (see <a href="http://twitter.com/rsarver/statuses/3437734477">here</a>).</p>

<p>Tying in location to the near-real-time nature of the Twitter timeline opens up lots of potential location-based applications. Let the slippy-mapping commence!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Consuming GeoRSS in ArcMap With InMemoryWorkspaceFactory]]></title>
    <link href="http://blog.geomusings.com/2007/07/10/consuming-georss-in-arcmap-with-inmemoryworkspacefactory/"/>
    <updated>2007-07-10T00:00:00-04:00</updated>
    <id>http://blog.geomusings.com/2007/07/10/consuming-georss-in-arcmap-with-inmemoryworkspacefactory</id>
    <content type="html"><![CDATA[<p>This will be my last post for a couple of weeks. I'm heading out to Florida tomorrow to spend time with my family and the Mouse. But before I head out, I thought I'd share a little something I've been working on.</p>

<p>I've been playing the last few days with the <a href="http://edndoc.esri.com/arcobjects/9.2/ComponentHelp/esriDataSourcesGDB/InMemoryWorkspaceFactory.htm">InMemoryWorkspaceFactory</a> class in ArcObjects. I am looking at using it for a project I will be working on when I get back so I thought I'd do a little prototyping beforehand.</p>

<p>The fact that it works in memory is very attractive, especially for using volatile data. <a href="http://georss.org/">GeoRSS</a> seemed like a natural source to use for prototyping.</p>

<!--more-->


<p>I wrote this in C# as a set of tools for ArcMap 9.2. The first thing I did was create a static reference to a single InMemoryWorkspaceFactory. It's a singleton anyway but this approach forces me to use a single entry point.</p>

<p>{% codeblock lang:csharp %}
public static void initInMemoryWorkspaceFactory()
{</p>

<pre><code>// Create an InMemory workspace factory.
InMemoryWorkspaceFactory workspaceFactory = new InMemoryWorkspaceFactoryClass();

// Create an InMemory geodatabase.
IWorkspaceName workspaceName = workspaceFactory.Create("", "GeoRssWorkspace", null, 0);

// Cast for IName.
IName name = (IName)workspaceName;

//Open a reference to the in-memory workspace through the name object.
IWorkspace inmemWor = (IWorkspace)name.Open();
m_memFeatWorkspace = (IFeatureWorkspace)inmemWor;
</code></pre>

<p>}
{% endcodeblock %}</p>

<p>Next, I created a custom FeatureLayer class called GeoRssFeatureLayer. It inherits from the ArcObjects FeatureLayer class and implements a custom interface called IGeoRssFeatureLayer. Using inheritance makes it easy to pass an instance around within ArcObjects and have it behave properly. Here's a snippet with the interface and class declaration:
{% codeblock lang:csharp %}
public interface IGeoRssFeatureLayer
{</p>

<pre><code>string Uri { get; set;}
void Refresh();
</code></pre>

<p>}</p>

<p>[Guid("a675765b-30d0-4294-ad98-28579c9f8994")]
[ClassInterface(ClassInterfaceType.None)]
[ProgId("ztGeoRss.GeoRssFeatureLayer")]
public class GeoRssFeatureLayer : ESRI.ArcGIS.Carto.FeatureLayerClass, IGeoRssFeatureLayer</p>

<pre><code>private string m_uri = string.Empty; 
private IFeatureClass m_fc = null; 
public GeoRssFeatureLayer(string uri) 
{ 
    m_uri = uri; 
    this.Refresh(); 
}
</code></pre>

<p>{% endcodeblock %}
I also added a constructor so I could pass in the URI directly. The IGeoRssFeatureLayer.Refresh method does most of the heavy lifting with some help from the loadFeatures method and a few statics in the Ambient class (it's a pretty name that gets the point across without conflicting with reserved words like "Environment"):
{% codeblock lang:csharp %}
public void Refresh()
{</p>

<pre><code>if (m_fc != null)
{
    Marshal.ReleaseComObject(m_fc);
}
m_fc = null; 
ISpatialReferenceFactory srf = new SpatialReferenceEnvironmentClass(); 
ISpatialReference sr = srf.CreateGeographicCoordinateSystem((int)esriSRGeoCSType.esriSRGeoCS_WGS1984); 
sr.SetDomain(-180, 180, -90, 90); 
IGeometryDefEdit gde = (IGeometryDefEdit)new GeometryDefClass(); 
gde.SpatialReference_2 = sr; 
gde.GeometryType_2 = esriGeometryType.esriGeometryPoint; 
gde.GridCount_2 = 1; 
gde.set_GridSize(0, 1000); 
IFieldsEdit fe = (IFieldsEdit)new FieldsClass(); 
fe.AddField(Ambient.makeField("OBJECTID", esriFieldType.esriFieldTypeOID, 0, null)); 
fe.AddField(Ambient.makeField("SHAPE", esriFieldType.esriFieldTypeGeometry, 0, (IGeometryDef)gde)); 
fe.AddField(Ambient.makeField("Title", esriFieldType.esriFieldTypeString, 100, null)); 
fe.AddField(Ambient.makeField("Description", esriFieldType.esriFieldTypeString, 300, null)); 
fe.AddField(Ambient.makeField("Link", esriFieldType.esriFieldTypeString, 100, null)); 
fe.AddField(Ambient.makeField("Author", esriFieldType.esriFieldTypeString, 100, null)); 
fe.AddField(Ambient.makeField("Comments", esriFieldType.esriFieldTypeString, 300, null)); 
fe.AddField(Ambient.makeField("PubDate", esriFieldType.esriFieldTypeString, 50, null)); 
fe.AddField(Ambient.makeField("Guid", esriFieldType.esriFieldTypeString, 50, null)); 
IFeatureWorkspace fws = Ambient.GeoRssWorkspace; 
m_fc = fws.CreateFeatureClass(System.Guid.NewGuid().ToString(), (IFields)fe, null, null, esriFeatureType.esriFTSimple, "Shape", ""); 
loadFeatures(); 
base.FeatureClass = m_fc; 
</code></pre>

<p>}</p>

<p>private void loadFeatures()
{</p>

<pre><code>RssFeed f = RssReader.GetFeed(m_uri);
base.Name = f.Title;
if (f.Items.Count &amp;gt; 0)
{
    //Cast for an IWorkspaceEdit        
    IWorkspaceEdit workspaceEdit = (IWorkspaceEdit)Ambient.GeoRssWorkspace;
    //Start an edit session and operation        
    workspaceEdit.StartEditing(true);        
    workspaceEdit.StartEditOperation();                
    //Create the Feature Buffer        
    IFeatureBuffer featureBuffer = m_fc.CreateFeatureBuffer();        
    //Create insert Feature Cursor using buffering = true.        
    IFeatureCursor featureCursor = m_fc.Insert(true);
    IPoint pt = new PointClass();
    int i;
    for (i = 0; (i &amp;lt;= (f.Items.Count - 1)); i++)
    {
        RssItem itm = f.Items[i];
        pt.X = Convert.ToDouble(itm.Longitude);
        pt.Y = Convert.ToDouble(itm.Latitude);
        featureBuffer.Shape = pt;
        featureBuffer.set_Value(2, itm.Title);
        featureBuffer.set_Value(3, itm.Description);
        featureBuffer.set_Value(4, itm.Link);
        featureBuffer.set_Value(5, itm.Author);
        featureBuffer.set_Value(6, itm.Comments);
        featureBuffer.set_Value(7, itm.Pubdate);
        featureBuffer.set_Value(8, itm.Guid);
        object oid = featureCursor.InsertFeature(featureBuffer);
    }                
    //Flush the feature cursor to the database        
    //Calling flush allows you to handle any errors at a known time rather then on the cursor destruction.        
    featureCursor.Flush();
    //Stop editing        
    workspaceEdit.StopEditOperation();        
    workspaceEdit.StopEditing(true);
    //Release the Cursor        
    System.Runtime.InteropServices.Marshal.ReleaseComObject(featureCursor);
}
</code></pre>

<p>}
}
{% endcodeblock %}</p>

<p>That pretty much does most of the real work. I have an ArcObjects command that actually instantiates the layer and adds it to ArcMap and there are a few helper functions as well. I snagged a good bit of other people's code to be able to turn around a prototype quickly so credit where credit is due:</p>

<ul>
    <li><a href="http://www.codeproject.com/KB/cs/rssreader.aspx">RssReader</a> on CodeProject - This handles the interaction with the feeds. I extended it to support geo tags</li>
    <li><a href="http://www.codeproject.com/cs/miscctrl/InputBox.asp">InputBox</a> on CodeProject - I used this to provide a simple means to allow the user to enter a URI.</li>
    <li>I also C#-ified some of <a href="http://ambergis.wordpress.com/">Kirk's</a> code I found on the ESRI forums</li>
    <li>I also grabbed a few lines from the ESRI help files</li>
</ul>


<p>I'll probably post an update when I get back but here's a screen capture. It depicts <a href="http://earthquake.usgs.gov/eqcenter/catalogs/eqs7day-M2.5.xml">USGS M2.5+ Earthquakes feed</a> and the path of <a href="http://krkinnan.members.winisp.net/georss/2004hurricaneivan.xml">Hurricane Ivan in 2004</a>. As of this writing, it only handles points in the "simple" formats.</p>

<p><a href="http://geobabble.files.wordpress.com/2007/07/georss_arcmap.png" title="GeoRSS in ArcMap"><img alt="GeoRSS in ArcMap" src="http://geobabble.files.wordpress.com/2007/07/georss_arcmap.thumbnail.png" /></a></p>

<p>Basically, I like the in-memory implementation because it allows for a pretty fast refresh plus it allows selections (note the selection of the last few positions of Ivan), identify (with automatic hyperlinking from the identify window) and other operations, make it a big plus over an XY event layer. It remains to be seen if there are any memory leaks but that'll come with further testing.</p>

<p><strong>UPDATE:</strong> Basically, the biggest problem with this approach right now is that a feature class can't contain multiple geometry types, regardless of the type of workspace. This is a big pain and makes management of a full GeoRSS feed (with points, lines and polygons) difficult. I'll post more when I get farther.</p>

<p><a href="http://www.statcounter.com/" target="_blank"><img alt="hit counter" border="0" src="http://c31.statcounter.com/2901378/0/be706774/0/" /></a></p>
]]></content>
  </entry>
  
</feed>
